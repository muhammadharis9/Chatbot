{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c22f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awan\n"
     ]
    }
   ],
   "source": [
    "print(\"awan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6bdacaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\chatbot\\\\Chatbot\\\\research'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "097dcc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e789234b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\chatbot\\\\Chatbot'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eafa52d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.document_loaders'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyPDFLoader\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.document_loaders'"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a10bbad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9d453fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls= PyPDFLoader\n",
    "    )\n",
    "\n",
    "    document = loader.load()\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f9c0f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_doc = load_pdf(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0e6a82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4b336cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9e0bdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 0, 'page_label': '1'}, page_content=''),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 1, 'page_label': '2'}, page_content='2\\nMastering AI Agents\\nPreface\\nIn our previous e-book, “Mastering RAG,” our goal was clear: building enterprise-grade \\nRAG systems, productionizing them, monitoring their performance, and improving them. \\nAt the core of it, we understood how RAG systems enhance an LLM’s ability to work with \\nspecific knowledge by providing relevant context. \\nIn this e-book, we’re taking a step further and asking, “How do we use LLMs to \\naccomplish end-to-end tasks?” This singular question opens up a door: AI agents. A RAG \\nsystem helps an LLM provide accurate answers based on given context. An AI agent \\ntakes that answer and actually does something with it — makes decisions, executes \\ntasks, or coordinates multiple steps to achieve a goal.\\nA RAG-enhanced LLM could help answer questions about policy details by pulling relevant \\ninformation. But an AI agent could actually process the claim end-to-end by analyzing the \\ndocumentation, checking policy compliance, calculating payments, and even coordinating \\nwith other systems or agents when needed. \\nThe ideas behind agents has existed for years. It can be a software program or another \\ncomputational entity that can accept input from its environment and take actions based \\non rules. With AI agents, you’re getting what has never been there before: the ability to \\nunderstand the context without predefined rules, the capacity to tune decisions based on \\ncontext, and learning from every interaction. What you’re getting is not just a bot working \\nwith a fixed set of rules but a system capable of making advanced decisions in real-time. \\nCompanies have quickly adapted, adopted, and integrated AI agents into their workflows. \\nCapgemini’s research found that “10% of organizations already use AI agents, more than \\nhalf plan to use them in 2025 and 82% plan to integrate them within the next three years.”'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 2, 'page_label': '3'}, page_content='3\\nMastering AI Agents\\nThis e-book aims to be your go-to guide for all things AI agents. If you’re a leader looking \\nto guide your company to build successful agentic applications, this e-book can serve \\nas a great guide to get you started. We also explore approaches to measuring how well \\nyour AI agents perform, as well as common pitfalls you may encounter when designing, \\nmeasuring, and improving them. \\nThe book is divided into five chapters: \\nChapter 1 introduces AI agents, their optimal applications, and scenarios where they \\nmight be excessive. It covers various agent types and includes three real-world use cases \\nto illustrate their potential. \\nChapter 2 details three frameworks—LangGraph, Autogen, and CrewAI—with evaluation \\ncriteria to help choose the best fit. It ends with case studies of companies using these \\nframeworks for specific AI tasks.\\nChapter 3 explores the evaluation of an AI agent through a step-by-step example of a \\nfinance research agent. \\nChapter 4 explores how to measure agent performance across systems, task completion, \\nquality control, and tool interaction, supported by five detailed use cases. \\nChapter 5 addresses why many AI agents fail and offers practical solutions for successful \\nAI deployment.\\nWe hope this book will be a great stepping stone in your journey to build trustworthy \\nagentic systems. \\n- Pratik Bhavsar'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 3, 'page_label': '4'}, page_content='Contents\\nTypes of AI Agents\\nWhen to Use Agents?\\nWhen Not to Use Agents?\\n10 Questions to Ask Before You \\nConsider an AI Agent\\n3 Interesting Real-World Use \\nCases of AI Agents\\n10 30\\n21\\n31\\n31\\n32\\n33\\n34\\n34\\n35\\n35\\n35\\n37\\n40\\n22\\n23\\n25\\nChapter 1:\\nWhat are AI agents\\nChapter 2:\\nFrameworks for \\nBuilding Agents\\nLangGraph vs. AutoGen vs. \\nCrewAI\\nPractical Considerations\\nWhat Tools and Functionalities Do \\nThey Support?\\nHow Well Do They Maintain the \\nContext?\\nAre They Well-Organized and Easy \\nto Interpret?\\nWhat’s the Quality of \\nDocumentation?\\nDo They Provide Multi-Agent \\nSupport?\\nWhat About Caching?\\nLooking at the Replay Functionality\\nWhat About Code Execution?\\nHuman in the Loop Support?\\nPopular Use Cases Centered \\nAround These Frameworks\\n7/27 28/43'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 4, 'page_label': '5'}, page_content='5\\nMastering AI Agents\\nRequirements\\nDefining the Problem\\nDefine the React Agent\\nState Management\\nCreate the Graph\\nCreate the LLM Judge\\nUse Galileo Callbacks\\n44\\n44\\n45\\n46\\n47\\n54\\n55\\n63\\n66\\n69\\n72\\n75\\nChapter 3:\\nHow to Evaluate Agents\\n44/61\\nChapter 4:\\nMetrics for Evaluating \\nAI Agents\\n62/79\\nCase Study 1: Advancing the \\nClaims Processing Agent\\nCase Study 2: Optimizing the Tax \\nAudit Agent\\nCase Study 3: Elevating the Stock \\nAnalysis Agent\\nCase Study 4: Upgrading the \\nCoding Agent\\nCase Study 5: Enhancing the Lead \\nScoring Agent'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 5, 'page_label': '6'}, page_content='6\\nMastering AI Agents\\nDevelopment Issues\\nLLM Issues\\nProduction Issues\\n81\\n82\\n86\\nChapter 5:\\nWhy Most AI Agents Fail & \\nHow to Fix Them\\n80/95'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 6, 'page_label': '7'}, page_content='WHAT ARE AI \\nAGENTS?\\n01 \\nCHAPTER'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 7, 'page_label': '8'}, page_content='8\\nMastering AI Agents\\nLet’s start by understanding what AI agents are and which tasks you should use them for \\nto maximize their potential.\\nAI agents are software applications that use large language models (LLMs) to \\nautonomously perform specific tasks, ranging from answering research questions to \\nhandling backend services. They’re incredibly useful for tasks that demand complex \\ndecision-making, autonomy, and adaptability. You might find them especially helpful in \\ndynamic environments where the workflow involves multiple steps or interactions that \\ncould benefit from automation.\\nSalesforce estimates that salespersons spend 71% of their time on non-selling tasks (like \\nadministrative tasks and manually entering data). Imagine the time that could have gone \\ninto directly engaging with customers, developing deeper relationships, and ultimately \\nclosing more sales. This is true across multiple domains and applications: finance, health \\ncare, tech, marketing, sales, and more. \\nLet’s use an example to understand this better. Imagine you run an online retail business \\nand receive hundreds of customer inquiries every day about order statuses, product \\ndetails, and shipping information. Instead of answering each and every query yourself, you \\ncan integrate an AI agent into your solution to handle these queries.\\nHere’s how it would typically work:\\n1. Customer Interaction\\nA customer messages your service asking, “When will my order ship?”\\n2. Data Retrieval\\nThe AI agent accesses the order management system to find the specific order details.\\n3. Response Generation\\nBased on the data retrieved, the agent automatically provides an updates to the customer, \\nsuch as sending “Your order will ship tomorrow and you’ll receive a tracking link via email \\nonce it’s on its way.”\\nWhat are AI agents?'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 8, 'page_label': '9'}, page_content='9\\nMastering AI Agents\\nThe return to having an AI agent is multifold here: \\n• Super quick response time that keeps your customers happy\\n• Frees up your human staff to handle more complex queries and issues\\n• Improves your overall productivity and efficiency\\nFig 1.1 is an example of how agents are leveraged for code generation.\\nSwitch to Backup\\nOpenAI GPT-4Actions\\nRepository\\nError <failure log>\\nWrite <file> <fix>\\nWrite <file> <content>\\nRetrieval signature \\nRun test\\nRun test\\nContent result\\nSuccess\\nConversation\\nAI Agent Eval Environment \\nUser\\nFig 1.1: Automated AI-Driven Development using AI agents'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 9, 'page_label': '10'}, page_content='10\\nMastering AI Agents\\nTypes of AI Agents\\nNow that we’re familiar with what AI agents are, let’s look at different types of AI \\nagents along with their characteristics, examples, and when you can use them. \\nSee Table 1.1 below to get a quick idea of the types of AI agents and where and \\nwhen you can use them.\\nName of the agent Key Characteristics Examples Best For\\nFixed Automation: The \\nDigital Assembly Line\\nNo intelligence, predictable \\nbehavior, limited scope\\nRPA, email \\nautoresponders, basic \\nscripts\\nRepetitive tasks, \\nstructured data, no need \\nfor adaptability\\nLLM-Enhanced: \\nSmarter, but Not \\nEinstein\\nContext-aware, rule-\\nconstrained, stateless\\nEmail filters, content \\nmoderation, support \\nticket routing\\nFlexible tasks, high-\\nvolume/low-stakes, cost-\\nsensitive scenarios\\nReAct: Reasoning \\nMeets Action\\nMulti-step workflows, \\ndynamic planning, basic \\nproblem-solving\\nTravel planners, AI \\ndungeon masters, \\nproject planning tools\\nStrategic planning, multi-\\nstage queries, dynamic \\nadjustments\\nReAct + RAG: \\nGrounded Intelligence\\nExternal knowledge \\naccess, low hallucinations, \\nreal-time data\\nLegal research tools, \\nmedical assistants, \\ntechnical support\\nHigh-stakes decisions, \\ndomain-specific tasks, \\nreal-time knowledge \\nneeds\\nTool-Enhanced: The \\nMulti-Taskers\\nMulti-tool integration, \\ndynamic execution, high \\nautomation\\nCode generation tools, \\ndata analysis bots\\nComplex workflows \\nrequiring multiple tools \\nand APIs\\nSelf-Reflecting: The \\nPhilosophers\\nMeta-cognition, \\nexplainability, self-\\nimprovement\\nSelf-evaluating systems, \\nQA agents\\nTasks requiring \\naccountability and \\nimprovement\\nMemory-Enhanced: \\nThe Personalized \\nPowerhouses\\nLong-term memory, \\npersonalization, adaptive \\nlearning\\nProject management AI, \\npersonalized assistants\\nIndividualized \\nexperiences, long-term \\ninteractions\\nEnvironment \\nControllers: The World \\nShapers\\nActive environment control, \\nautonomous operation, \\nfeedback-driven\\nAutoGPT, adaptive \\nrobotics, smart cities\\nSystem control, IoT \\nintegration, autonomous \\noperations\\nSelf-Learning: The \\nEvolutionaries\\nAutonomous learning, \\nadaptive/scalable, \\nevolutionary behavior\\nNeural networks, swarm \\nAI, financial prediction \\nmodels\\nCutting-edge research, \\nautonomous learning \\nsystems\\nTable 1.1: Types of agents and their characteristics'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 10, 'page_label': '11'}, page_content='11\\nMastering AI Agents\\nPredefined \\nRule\\nSend Output / \\nResult\\nThis level of AI agents represents the simplest and most rigid form of automation. These \\nagents don’t adapt or think—they just execute pre-programmed instructions. They are \\nlike assembly-line workers in a digital factory: efficient but inflexible. Great for repetitive \\ntasks, but throw them a curveball, and they’ll freeze faster than Internet Explorer.\\n(See Table 1.2 below)\\nThe fixed automation workflow (See Fig 1.2) follows a simple, linear path. It begins when \\na specific input (like a file or data) triggers the system, which consults its predefined \\nrulebook to determine what to do. Based on these rules, it executes the required action \\nand finally sends out the result or output. Think of it as a digital assembly line where \\neach step must be completed in exact order, without deviation.\\nFixed Automation – \\nThe Digital Assembly Line\\nTable 1.2: Characteristics of a fixed automation agent\\nFig 1.2: Workflow of a fixed automation agent\\nFeature Description\\nIntelligence No learning, adaptation, or memory.\\nBehavior Predictable and consistent, follows pre-defined rules.\\nScope Limited to repetitive, well-defined tasks. Struggles with unexpected scenarios.\\nBest Use Cases Routine tasks, structured data, situations with minimal need for adaptability.\\nExamples RPA for invoice processing, email autoresponders, basic scripting tools (Bash, \\nPowerShell).\\nFixed Automation Agent\\nInput Trigger Execute \\nAction'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 11, 'page_label': '12'}, page_content='12\\nMastering AI Agents\\nLLM\\n(contextual analysis)\\nOutput / \\nAction\\nThese agents leverage LLMs to provide contextual understanding and handle \\nambiguous tasks while operating within strict boundaries. LLM-Enhanced Agents \\nbalance intelligence and simplicity, making them highly efficient for low-complexity, \\nhigh-volume tasks. Take a look at their features below in Table 1.3.\\nThe workflow below (Fig 1.3) shows how these smarter agents process information: \\nstarting with the input, the agent uses LLM capabilities to analyze and understand \\nthe input context. This analysis then passes through rule-based constraints that keep \\nthe agent within defined boundaries, producing an appropriate output. It’s like having \\na smart assistant who understands context but still follows company policy before \\nmaking decisions.\\nLLM-Enhanced –\\nSmarter, but Not Exactly Einstein\\nTable 1.3: Characteristics of an LLM-enhanced agent\\nFig 1.3: Workflow of a LLM-enhanced agent\\nFeature Description\\nIntelligence Context-aware; leverages LLMs to process ambiguous inputs with contextual \\nreasoning.\\nBehavior Rule-constrained; decisions are validated against predefined rules or thresholds.\\nScope Stateless; no long-term memory; each task is processed independently.\\nBest Use Cases Tasks requiring flexibility with ambiguous inputs, high-volume/low-stakes \\nscenarios, and cost-sensitive situations where \"close enough\" is sufficient.\\nExamples Email filters, AI-enhanced content moderation, customer support classification.\\nLLM-Enhanced Agent\\nInput Data Rule-based \\nConstraint'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 12, 'page_label': '13'}, page_content='13\\nMastering AI Agents\\nReasoning \\nrepeat until desired outcome achieved Output / \\nAction\\nReAct agents combine Reasoning and Action to perform tasks that involve strategic \\nthinking and multi-step decision-making. They break complex tasks into manageable \\nsteps, reasoning through problems dynamically and acting based on their analysis. \\nThese agents are like your type-A friend who plans their weekend down to the minute. \\nTable 1.4 lists their characteristics.\\nThe ReAct workflow starts with an Input Query and then enters a dynamic cycle between \\nthe Reasoning and Action Phase, as you’ll see in Fig 1.4. Unlike simpler agents, it can \\nloop between thinking and acting repeatedly until the desired outcome is achieved before \\nproducing the final Output/Action. Think of it as a problem solver that keeps adjusting its \\napproach - analyzing, trying something, checking if it worked, and trying again if needed.\\nReAct – \\nReasoning Meets Action\\nTable 1.4: Characteristics of a fixed ReAct agent\\nFig 1.4: Workflow of a ReAct agent\\nFeature Description\\nIntelligence Reasoning and action; mimics human problem-solving by thinking through a \\nproblem and executing the next step.\\nBehavior Handles multi-step workflows, breaking them down into smaller, actionable parts. \\nDynamically adjusts strategy based on new data.\\nScope Assists with basic open-ended problem-solving, even without a direct solution path.\\nBest Use Cases Strategic planning, multi-stage queries, tasks requiring dynamic adjustments, and \\nre-strategizing.\\nExamples Language agents solving multi-step queries, AI Dungeon Masters, project planning \\ntools.\\nFixed Automation Agent\\nInput Trigger\\nAction Phase'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 13, 'page_label': '14'}, page_content='14\\nMastering AI Agents\\nReasoning \\nrepeat until desired outcome achieved Output / \\nAction\\nNow, moving on to agents who are much more intelligent, we come to ReAct + RAG \\nagents that combine reasoning, action, and real-time access to external knowledge \\nsources. This integration allows them to make informed decisions grounded in accurate, \\ndomain-specific data, making them ideal for high-stakes or precision-critical tasks \\n(especially when you add evaluations). These agents are your ultimate trivia masters with \\nGoogle on speed dial. See Table 1.5 to learn how this agent works.\\nStarting with an Input Query, this advanced workflow combines ReAct’s reasoning-action \\nloop with an additional Knowledge Retrieval step. The agent cycles between Reasoning, \\nAction Phase, and Knowledge Retrieval (See Fig 1.5) — consulting external sources as \\nneeded — until it reaches the desired outcome and produces an Output/Action. It’s like \\nhaving a problem solver who not only thinks and acts but also fact-checks against reliable \\nsources along the way.\\nReAct + RAG – Grounded Intelligence\\nTable 1.5: Characteristics of a ReAct + RAG agent\\nFig 1.5: Workflow of a ReAct + RAG agent\\nFeature Description\\nIntelligence Employs a RAG workflow, combining LLMs with external knowledge sources \\n(databases, APIs, documentation) for enhanced context and accuracy.\\nBehavior Uses ReAct-style reasoning to break down tasks, dynamically retrieving information \\nas needed. Grounded in real-time or domain-specific knowledge.\\nScope Designed for scenarios requiring high accuracy and relevance, minimizing \\nhallucinations.\\nBest Use Cases High-stakes decision-making, domain-specific applications, tasks with dynamic \\nknowledge needs (e.g., real-time updates).\\nExamples Legal research tools, medical assistants referencing clinical studies, technical \\ntroubleshooting agents.\\nReAct + RAG Agent\\nInput Query\\nKnowledge \\nRetrievalAction Phase'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 14, 'page_label': '15'}, page_content=\"15\\nMastering AI Agents\\nReasoning \\nrepeat until desired outcome achieved Output / \\nAction\\nTool-enhanced agents are versatile problem solvers that integrate multiple tools, \\nleveraging APIs, databases, and software to handle complex, multi-domain workflows. \\nThey combine reasoning, retrieval, and execution for seamless, dynamic task \\ncompletion. Think of them as tech-savvy Swiss Army knives capable of combining \\nreasoning, retrieval, and execution seamlessly! (See Table 1.6) \\nStarting with an Input Query, the agent combines reasoning with a specialized tool loop. \\nAfter the initial reasoning phase, it selects the appropriate tool for the task (Tool Selection) \\nand then executes it (Tool Execution). This cycle repeats until the desired outcome is \\nachieved, leading to the final Output/Action. (See Fig 1.6)\\nTool-Enhanced – The Multi-Taskers\\nTable 1.6: Characteristics of tool-enhanced agents\\nFig 1.6: Workflow of tool-enhanced agents\\nFeature Description\\nIntelligence Leverages APIs, databases, and software tools to perform tasks, acting as a multi-\\ntool integrator.\\nBehavior Handles multi-step workflows, dynamically switching between tools based on task \\nrequirements.\\nScope Automates repetitive or multi-stage processes by integrating and utilizing diverse \\ntools.\\nBest Use Cases Jobs requiring diverse tools and APIs in tandem for complex or multi-stage \\nautomation.\\nExamples Code generation tools (GitHub CoPilot, Sourcegraph's Cody, Warp Terminal), data \\nanalysis bots combining multiple APIs.\\nTool Enhanced Agent\\nInput Query\\nTool SelectionTool Execution\"),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 15, 'page_label': '16'}, page_content='16\\nMastering AI Agents\\nThese agents think about their thinking. Self-reflecting agents introduce meta-\\ncognition—they analyze their reasoning, assess their decisions, and learn from mistakes. \\nThis enables them to solve tasks, explain their reasoning, and improve over time, \\nensuring greater reliability and accountability. (See Table 1.7) \\nStarting with an Input Query, the agent goes through a cycle of Reasoning and Execution, \\nbut with a crucial additional step: Reflection. After each execution, it reflects on its \\nperformance and feeds those insights back into its reasoning process. This continuous \\nloop of thinking, doing, and learning continues until the desired outcome is achieved, \\nproducing the final Output/Action. This is evident in Fig 1.7.\\nSelf-Reflecting – The Philosophers\\nTable 1.7: Characteristics of self-reflecting agents\\nFig 1.7: Workflow of self-reflecting agents\\nFeature Description\\nIntelligence Exhibits meta-cognition, evaluating its own thought processes and decision \\noutcomes.\\nBehavior Provides explanations for actions, offering transparency into its reasoning. Learns \\nfrom mistakes and improves performance over time.\\nScope Suited for tasks requiring accountability and continuous improvement.\\nBest Use Cases Quality assurance, sensitive decision-making where explainability and self-\\nimprovement are crucial.\\nExamples AI that explains its reasoning, self-evaluating learning systems, quality assurance \\n(QA) agents.\\nInput Query Output / \\nAction\\nExecution\\nReasoning Reflection\\nFeedback Loop\\nWhen \\ndesired \\noutcome \\nachived'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 16, 'page_label': '17'}, page_content='17\\nMastering AI Agents\\nGive an agent a little memory, and you have the ultimate personal assistant. Memory-\\nenhanced agents bring personalization to the forefront by maintaining historical context \\nand remembering user preferences, previous interactions, and task history. They act as \\nadaptive personal assistants, providing tailored experiences and continuous, context-\\naware support. These agents remember your preferences, track your history, and \\ntheoretically — would never (ever) forget your coffee order! (See Table 1.8) \\nLook at Fig 1.8: Starting with an Input Query, this agent first recalls relevant past \\nexperiences and preferences (Memory Recall), then uses this context for Reasoning about \\nthe current task. After deciding on a course of action, it executes it (Action/Execution), \\nupdates its memory with new information (Memory Update), and produces the Output. \\nMemory-Enhanced –\\nThe Personalized Powerhouses\\nTable 1.8: Characteristics of memory-enhanced agents\\nFig 1.8: Workflow of memory-enhanced agents\\nFeature Description\\nIntelligence Possesses long-term memory, storing and recalling past interactions, preferences, \\nand task progress.\\nBehavior Provides context-aware personalization, adapting decisions and actions based on \\nuser-specific data and history. Learns and improves over time.\\nScope Excels at tasks requiring individualized experiences, tailored recommendations, and \\nmaintaining consistency across multiple interactions.\\nBest Use Cases Personalized assistance, long-term interactions, tasks spanning multiple sessions.\\nExamples Project management AI with task history, customer service bots tracking \\ninteractions, personalized shopping assistants.\\nInput Query Memory \\nUpdate\\nReasoning \\nPhase\\nAction / \\nExecution\\nMemory \\nRecall Output\\nUpdates Long-term Memory'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 17, 'page_label': '18'}, page_content='18\\nMastering AI Agents\\nEnvironment-controlling agents extend beyond decision-making and interaction—they \\nactively manipulate and control environments in real time. These agents are equipped \\nto perform tasks that influence the digital landscape or the physical world, making \\nthem ideal for applications in automation, robotics, and adaptive systems. Think smart \\nthermostats, but on steroids! (See Table 1.9)\\nObserve the workflow in Fig 1.9 carefully. Starting with an Input Query, the agent first \\nobserves its surroundings (Perception Phase), reasons about the current state and \\nrequired changes (Reasoning Phase), takes action to modify the environment (Action \\nPhase), and then receives feedback about the changes (Feedback Phase). This cycle \\nrepeats until the desired goal is met, producing both an Output and changed system state. \\nEnvironment Controllers –\\nThe World Shapers\\nTable 1.9: Characteristics of environment-controlling agents\\nFig 1.9: Workflow of an environment-controlled agent\\nFeature Description\\nIntelligence Autonomous learning; refines models and processes based on feedback, data, or \\nenvironmental changes without manual updates.\\nBehavior Adaptive and scalable, adjusting to changing conditions and new tasks. Exhibits \\nevolutionary behavior, improving performance over time.\\nScope Suited for cutting-edge research and autonomous learning systems, offering high \\npotential but requiring careful monitoring.\\nBest Use Cases Situations where autonomous learning and adaptation are crucial, such as complex \\nresearch, simulation, or dynamic environments.\\nExamples Neural networks with evolutionary capabilities, swarm AI systems, autonomous \\nrobotics, financial prediction models.\\nInput Query Action \\nPhase\\nReasoning \\nPhase\\nOutput + \\nChanged State\\n Perception \\nPhase\\nFeedback \\nPhase\\nIterate until goal met\\nEnvironment Control Loop\\nGoal achieved'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 18, 'page_label': '19'}, page_content='19\\nMastering AI Agents\\nThe holy grail of AI agents: those that can improve themselves over time. They learn, \\nadapt, and evolve without needing constant babysitting. These agents improve \\nthemselves over time, learning from interactions, adapting to new environments, and \\nevolving without constant human intervention. They combine elements of reasoning, \\nmemory, environment control, and self-reflection with autonomous learning capabilities \\nto adapt and optimize their behavior. \\nAre they the future of AI? Potentially. Are they also terrifying? Without evaluations, \\nobservation, regulation, and oversight, very much so. \\nFrom the workflow in Fig 1.10, you’ll realize how a self-learning agent are akin to an AI \\nresearcher that gets smarter with every experiment, constantly refining its methods and \\nknowledge. \\nStarting with an Input Query, the agent enters a continuous cycle beginning with the \\nLearning Phase where it processes available data, moves to Reasoning to analyze it, then \\ntakes Actions based on its analysis. The Feedback Phase evaluates results, leading to \\nan Evolution Phase where the agent adapts and improves its models. This cycle repeats \\ncontinuously, producing not just an Output but an evolved version of both the solution and \\nthe agent itself.\\nSelf-Learning – The Evolutionaries\\nTable 1.10: Self-learning agents’ characteristics\\nFeature Description\\nIntelligence Autonomous learning; refines models and processes based on feedback, data, or \\nenvironmental changes without manual updates.\\nBehavior Adaptive and scalable, adjusting to changing conditions and new tasks. Exhibits \\nevolutionary behavior, improving performance over time.\\nScope Suited for cutting-edge research and autonomous learning systems, offering high \\npotential but requiring careful monitoring.\\nBest Use Cases Situations where autonomous learning and adaptation are crucial, such as complex \\nresearch, simulation, or dynamic environments.\\nExamples Neural networks with evolutionary capabilities, swarm AI systems, autonomous \\nrobotics, financial prediction models.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 19, 'page_label': '20'}, page_content='20\\nMastering AI Agents\\nFig 1.10: Workflow of a self-learning agent\\nInput Query Evolution \\nPhase\\nLearning \\nPhase\\nOutput + \\nEvolved Agent\\nReasoning \\nPhas\\nFeedback \\nPhase\\nAction Phase\\nEnvironment Control Loop\\nSolution Ready\\nContinuous Iteration\\nWhat’s fascinating is that each type has its own sweet spot—there’s no “one-size-fits-\\nall” solution. The key is matching the right agent type to your specific needs, whether \\nyou need the reliable consistency of fixed automation for routine tasks or the adaptive \\nintelligence of self-learning agents for cutting-edge research.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 20, 'page_label': '21'}, page_content='21\\nMastering AI Agents\\nWe’ve looked at the agent types and where each one excels. That said, you still need to \\nbe able to gauge where you’ll need an AI agent. Agents are highly beneficial when tasks \\nrequire complex decision-making, autonomy, and adaptability. They excel in environments \\nwhere the workflow is dynamic and involves multiple steps or interactions that can benefit \\nfrom automation. You’ll see how workflows in different domains can benefit from the use of \\nAI agents in Table 1.11 below:\\nDomain Task Benefits of Using AI Agents\\nCustomer Support\\nHandling queries, providing \\nreal-time assistance, issue \\nescalation\\nAgents enhance the efficiency and customer \\nexperience by offering timely and accurate \\nresponses, allowing human staff to focus on more \\ncomplex issues.\\nResearch and Data \\nAnalysis\\nGathering, processing, and \\nanalyzing data\\nThey autonomously provide deep insights from \\nlarge datasets, helping you understand patterns \\nwithout manual effort.\\nFinancial Trading Real-time data processing Agents excel in making quick decisions based on \\nrapidly-changing market conditions.\\nEducation Personalized learning \\nexperiences\\nThese agents adapt to each student’s learning \\npace, offering tailored feedback and supporting \\nunique learning journeys effectively.\\nSoftware \\nDevelopment\\nCode generation, debugging, \\nand testing\\nAgents streamline the development process by \\nhandling repetitive tasks like coding and testing, \\nimproving code quality, and reducing development \\ntime. They also learn and improve over time, which \\ncontinually enhances their assistance.\\nTable 1.11: Domains and applications that can benefit from the use of AI agents\\nWhen to Use Agents?'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 21, 'page_label': '22'}, page_content='22\\nMastering AI Agents\\nAgents offer many advantages, but there are certain scenarios in which deploying them \\nmight not be the best option.\\nIf the tasks you’re dealing with are straightforward, occur infrequently, or require only \\nminimal automation, the complexity and cost of implementing AI agents might not make \\nsense for you. Simple tasks that existing software solutions can handle efficiently do not \\nnecessarily benefit from the added intricacy of agent-based systems. In such cases, \\nsticking with traditional methods can be more efficient and cost-effective.\\nAlso, if your tasks require deep domain-specific knowledge or expertise—like conducting \\ncomplex legal analyses, making intricate medical diagnoses, or handling high-stakes \\ndecision-making in unpredictable environments—these are typically better left to \\nexperienced professionals. When you rely solely on agents for these critical tasks, it can \\nlead to suboptimal or even harmful outcomes.\\nThat said, fields like psychotherapy, counseling, or creative writing thrive on the nuances \\nof human emotion and the creative process—areas where agents largely fall short. In \\nthese domains, the human touch is irreplaceable and essential for achieving meaningful \\noutcomes.\\nImplementing agents also requires a significant investment from you in terms of time, \\nresources, and expertise. If you’re running a small business or managing a project with \\na tight budget, the costs of developing and maintaining these agents may not justify \\nthe benefits. In highly regulated industries, your use of agents might be restricted due \\nto compliance and security concerns as well, and ensuring agents adhere to stringent \\nregulatory requirements can be very challenging and resource-intensive.\\nWhen Not to Use Agents?'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 22, 'page_label': '23'}, page_content='23\\nMastering AI Agents\\nBefore you consider using AI agents, you’ll need to ask yourself a set of questions to help \\nyou evaluate if it’s actually worth the time, capital, and resources you’ll be putting into it:\\n10 Questions to Ask Before \\nYou Consider an AI Agent\\nIs the task simple and repetitive, \\nor does it involve complex \\ndecision-making that could benefit \\nfrom automation?\\nWill the agent be handle large \\nvolumes of data or queries where \\nspeed and efficiency are crucial?\\nIs there a benefit to having a system \\nthat learns from its interactions and \\nimproves its responses or strategies \\nover time?\\nIs this a frequent task where \\nautomation could save significant time \\nand resources, or is it a rare event \\nthat might not justify the investment?\\nAre the conditions under which \\nthe task is performed constantly \\nchanging, requiring adaptive \\nresponses that an AI can manage?\\nIs it critical that the task is performed \\nwith high accuracy, such as in \\nmedical or financial settings, where AI \\nmight need to meet high standards?\\n01\\n03\\n05\\nWhat is the complexity \\nof the task?\\nWhat is the \\nexpected volume of \\ndata or queries?\\nCan the task benefit \\nfrom learning and \\nevolving over time?\\n02\\nHow often does the \\ntask occur?\\n04\\n06\\nDoes the task require \\nadaptability?\\nWhat level of accuracy \\nis required?'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 23, 'page_label': '24'}, page_content='24\\nMastering AI Agents\\nTake time to evaluate these questions; this will help you better \\ndetermine if an AI agent fits your needs and how it could be \\neffectively implemented to enhance your operations or services.\\nDoes the task require deep domain \\nknowledge, human intuition, or \\nemotional empathy that AI currently \\ncannot provide?\\nAre there specific industry regulations \\nor compliance issues that need to be \\naddressed when using AI?\\nDoes the task involve sensitive \\ninformation that must be handled with \\nstrict privacy and security measures?\\nDoes the return on investment in \\nterms of time saved, efficiency \\ngained, and overall performance \\noutweigh the costs of implementing \\nand maintaining an AI system?\\n07\\n09\\n08\\n10\\nIs human expertise or \\nemotional intelligence \\nessential?\\nWhat are the regulatory \\nand compliance \\nrequirements?\\nWhat are the \\nprivacy and security \\nimplications?\\nWhat is the cost-\\nbenefit analysis?'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 24, 'page_label': '25'}, page_content='25\\nMastering AI Agents\\nNow that we’ve learned what agents are and when to and when not to use them, it’s time \\nto go through some interesting real-world use cases of AI agents. \\nCompany:\\nWiley\\nProblem:\\nWiley faced challenges handling \\nspikes in service calls during peak \\ntimes, particularly at the start of new \\nsemesters when thousands of students \\nuse Wiley’s educational resources.\\nSolution:\\nWiley invested in Salesforce’s Agentforce, an AI agent \\ndesigned to enhance customer service operations. \\nThis integration has significantly improved case \\nresolution rates and faster resolution of customer \\nqueries, especially during peak times, such as the \\nstart of new semesters when demand spikes.\\nNeed:\\nThe company needed an \\nefficient customer service \\nsystem to manage the \\nincreased volume and maintain \\npositive customer experiences.\\nROI:\\nA 40%+ increase in case \\nresolution compared to \\ntheir previous chatbot, a \\n213% ROI, and $230K \\nin savings\\nAI Agent:\\nAgentforce by Salesforce\\nUse Case:\\nCustomer service automation\\n3 Interesting Real-World \\nUse Cases of AI Agents\\n1. Wiley and Agentforce'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 25, 'page_label': '26'}, page_content='26\\nMastering AI Agents\\nNeed:\\nThere was a need for a solution that \\ncould streamline clinical workflows \\nand improve documentation \\naccuracy while allowing providers \\nmore time to interact with patients.\\nCompany:\\nOracle Health\\nUse Case:\\nEnhancing patient-\\nprovider interactions\\nProblem:\\nHealthcare providers faced \\ndocumentation and time \\nmanagement challenges during \\npatient visits, leading to burnout \\nand reduced patient engagement.\\nSolution:\\nOracle Health developed its \\nClinical AI Agent, which automates \\ndocumentation processes and \\nenhances patient-provider interactions \\nthrough a multimodal voice user \\ninterface. This allows providers to \\naccess patient information quickly and \\ngenerate accurate notes efficiently.\\nROI:\\nAtlantiCare, using the Clinical AI \\nAgent, reported a 41% reduction \\nin total documentation time, \\nsaving approximately 66 minutes \\nper day, which translates to \\nimproved productivity and \\nenhanced patient satisfaction.\\nAI Agent:\\nClinical AI Agen\\n2. Oracle Health and Clinical AI agent'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 26, 'page_label': '27'}, page_content='27\\nMastering AI Agents\\nCompany:\\nMagid\\nProblem:\\nMagid, a leader in consumer intelligence \\nfor media brands, needed to ensure \\nconsistent, high-quality content in a fast-\\npaced news environment. The complexity \\nof diverse topics made it challenging \\nto uphold accuracy, and errors could \\npotentially lead to significant repercussions.\\nSolution:\\nMagid integrated Galileo’s real-time \\nobservability capabilities into their \\nproduct ecosystem. This integration \\nprovided production monitoring, \\nrelevant metrics for tracking tone \\nand accuracy, and customization \\noptions tailored to Magid’s needs.\\nNeed:\\nA robust observability system \\nwas essential for monitoring AI-\\ndriven workflows and ensuring \\nthe quality of outputs across \\nvarious clients. This scalability \\nwas crucial for managing the daily \\nproduction of numerous stories.\\nROI:\\nWith Galileo, Magid achieved 100% \\nvisibility over inputs and outputs, \\nenabling customized offerings \\nas they scale. This visibility helps \\nidentify trends and develop client-\\nspecific metrics, enhancing the \\naccuracy of news delivery.\\nAI Agent:\\nRAG-based system \\npowered with real-time \\nobservability capabilities\\nUse Case:\\nEmpowering newsrooms \\nwith generative AI technology\\n3. Magid and Galileo\\nWe’ll look at many more use cases across multiple \\ndomains throughout the rest of this e-book. We’ll \\nexamine how agents have driven greater\\nproductivity, quicker resolutions, and helped \\nthings get done faster.\\nIn the next chapter, we’re going to learn features \\nof three prominent frameworks for building AI \\nagents. Lots of exciting stuff ahead!'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 27, 'page_label': '28'}, page_content='FRAMEWORKS FOR \\nBUILDING AGENTS\\n02 \\nCHAPTER'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 28, 'page_label': '29'}, page_content='29\\nMastering AI Agents\\nCHAPTER 2\\nFRAMEWORKS FOR \\nBUILDING AGENTS\\nThe first chapter examined what AI agents are and when to use them. Before we move on \\nto the frameworks you can use to build these agents, let’s do a quick recap.\\nAI agents are particularly useful for dynamic, complex environments like customer support \\nor data-heavy sectors such as finance, where they automate and speed up processes. \\nThey’re also great for personalizing education and streamlining software development. \\nHowever, they are not ideal for straightforward tasks that traditional software efficiently \\nhandles or for fields requiring deep expertise, empathy, or high-stakes decision making, \\nwhere human judgment is crucial. The cost and regulatory compliance may also make \\nthem less viable for small projects or heavily regulated industries.\\nThat said, the framework you choose to build these agents can significantly affect their \\nefficiency and effectiveness. In this chapter, we’ll evaluate three prominent frameworks for \\nbuilding AI agents — LangGraph, Autogen, and CrewAI — to help you make an informed \\nchoice.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 29, 'page_label': '30'}, page_content='30\\nMastering AI Agents\\nLangGraph vs. Autogen vs. CrewAI\\nLangGraph is an open-source framework designed by Langchain to build stateful, multi-\\nactor applications using LLMs. Inspired by the long history of representing data processing \\npipelines as directed acyclic graphs (DAGs), LangGraph treats workflows as graphs where \\neach node represents a specific task or function. \\nThis graph-based approach allows for fine-grained control over the flow and state of \\napplications, making it particularly suitable for complex workflows that require advanced \\nmemory features, error recovery, and human-in-the-loop interactions. LangGraph \\nintegrates seamlessly with LangChain, providing access to various tools and models and \\nsupporting various multi-agent interaction patterns.\\nBelow are three frameworks you can consider when building AI agents:\\nLangGraph\\nAutogen is a versatile framework developed by Microsoft for building conversational \\nagents. It treats workflows as conversations between agents, making it intuitive for users \\nwho prefer interactive ChatGPT-like interfaces. \\nAutogen supports various tools, including code executors and function callers, allowing \\nagents to perform complex tasks autonomously. The highly customizable framework \\nallows you to extend agents with additional components and define custom workflows. \\nAutogen is designed to be modular and easy to maintain, making it suitable for both simple \\nand complex multi-agent scenarios.\\nAutogen\\nCrewAI is a framework designed to facilitate the collaboration of role-based AI agents. \\nEach agent in is assigned specific roles and goals, allowing them to operate as a cohesive \\nunit. This framework is ideal for building sophisticated multi-agent systems such as multi-\\nagent research teams. CrewAI supports flexible task management, autonomous inter-\\nagent delegation, and customizable tools.\\nCrewAI'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 30, 'page_label': '31'}, page_content='31\\nMastering AI Agents\\nPractical Considerations \\nFor practical consideration, let’s compare LangGraph, Autogen, and CrewAI across several \\nkey aspects.\\nHow easy are they to use? \\nEase of use determines how quickly and efficiently you can start using a framework. It also \\naffects the learning curve and the time required to build and deploy agents.\\nConsider LangGraph. This framework visualizes workflows as graphs using directed \\nacyclic graphs (DAGs). You’ll find this approach intuitive if you’re familiar with data \\nprocessing pipelines. It makes it easier for you to visualize and manage complex \\ninteractions. You might need a deeper understanding of graph theories, which could \\ninitially steepen your learning curve.\\nThen there’s Autogen, which models workflows as conversations between agents. If you \\nprefer interactive, chat-based environments, this framework will likely feel more natural to \\nyou. Autogen simplifies the management of agent interactions, allowing you to focus more \\non defining tasks and less on the underlying complexities. This can be a great help when \\nyou’re just starting out.\\nCrewAI, on the other hand, focuses on role-based agent design, where each agent has \\nspecific roles and goals. This framework is designed to enable AI agents to operate as \\na cohesive unit, which can be beneficial for building complex, multi-agent systems. It \\nprovides a structured approach to defining and managing agents. It’s very straightforward \\nto get started with CrewAI.\\nWinner: Autogen and CrewAI have an edge due to their conversational approach and \\nsimplicity.\\nWhat tools and functionalities do they support? \\nTool coverage is an essential aspect you’ll want to consider when evaluating a framework. \\nIt refers to the range of tools and functionalities that a framework supports, enhancing the \\ncapabilities of your agents.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 31, 'page_label': '32'}, page_content='32\\nMastering AI Agents\\nFor instance, LangGraph offers robust integration with LangChain, which opens up a wide \\narray of tools and models for your use. It supports functionalities like tool calling, memory, \\nand human-in-the-loop interactions. This comprehensive integration allows you to tap \\ninto a broad ecosystem, significantly extending your agents’ functionality. If your project \\nrequires a rich toolkit for complex tasks, LangGraph’s capabilities might be particularly \\nvaluable.\\nMoving on to Autogen, this framework stands out with its support for various tools, \\nincluding code executors and function callers. Its modular design is a key feature, \\nsimplifying the process of adding and integrating new tools as your project evolves. If \\nflexibility and scalability are high on your list, Autogen’s approach lets you adapt and \\nexpand your toolset as needed without much hassle.\\nLastly, CrewAI is built on top of LangChain, which means it inherits access to all of \\nLangChain’s tools. It allows you to define and integrate custom tools tailored to your \\nspecific needs. This capability is ideal if you’re looking to craft a highly customized \\nenvironment for your agents.\\nWinner: LangGraph and Crew have an edge due to their seamless integration with \\nLangChain, which offers a comprehensive range of tools. All the frameworks allow the \\naddition of custom tools.\\nHow well do they maintain context? \\nMemory support is crucial for agents to maintain context across interactions, enabling \\nthem to provide more coherent and relevant responses. There are different types of \\nmemory that agents can use:\\nMemory Type Description\\nShort-Term Memory Keeps track of recent interactions and outcomes.\\nLong-Term Memory Stores insights and learnings from past interactions.\\nEntity Memory Focuses on capturing details about specific entities.\\nContextual Memory Integrates short-term, long-term, and entity memories.\\nTable 2.1: Memory types that agents can use'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 32, 'page_label': '33'}, page_content='33\\nMastering AI Agents\\nLangGraph supports built-in short-term, long-term, and entity memory, enabling agents to \\nmaintain context across interactions. It includes advanced features like error recovery and \\nthe ability to revisit previous states, which are helpful for complex problem-solving.\\nAutogen employs a conversation-driven approach to support memory, enabling agents \\nto remember previous interactions and stay contextually aware. This setup ensures that \\nagents maintain a coherent context throughout their interactions, which is essential for \\ntasks that depend on continuity.\\nCrewAI features a comprehensive memory system that includes short-term, long-term, and \\nentity memory. This system allows agents to accumulate experiences and enhance their \\ndecision-making capabilities over time, ensuring they can recall important details across \\nmultiple interactions.\\nWinner: Both LangGraph and CrewAI have an edge due to their comprehensive memory \\nsystem, which includes short-term, long-term, and entity memory.\\nAre They Well-Organized and Easy to Interpret? \\nStructured output is vital for ensuring that the responses generated by agents are well-\\norganized and easily interpretable. Structured output can include JSON, XML, or other \\nformats that facilitate further processing and analysis.\\nLangGraph allows nodes to return structured output, which can be used to route to \\nthe next step or update the state. This makes managing complex workflows easier and \\nensures the output is well-organized. An ideal use case is a customer service system that \\nroutes queries through different departments based on content analysis, urgency, and \\nprevious interaction history. \\nAutogen supports structured output through its function-calling capabilities. Agents can \\ngenerate structured responses based on the tools and functions they use. This ensures \\nthat the output is well-defined and can be easily processed by other components. A \\ncoding assistant system where multiple specialized agents (code writer, reviewer, tester) \\nneed to work together dynamically is a good use case to think of. \\nCrewAI supports structured output by allowing agents to parse outputs as Pydantic \\nmodels or JSON. This ensures that the output is well-organized and easily interpretable. \\nYou can define the structure of the output to meet their specific requirements. For \\nexample, consider a data processing pipeline in which multiple agents need to transform \\nand validate data according to specific schemas.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 33, 'page_label': '34'}, page_content='34\\nMastering AI Agents\\nWinner: LangGraph and CrewAI have an edge due to their ability to define structured \\noutput.\\nWhat’s the Quality of Documentation? \\nDocumentation quality affects how easily developers can understand and use the \\nframework. Good documentation can reduce the learning curve and improve the overall \\ndeveloper experience.\\nLangGraph provides comprehensive documentation, including detailed guides and \\nexamples. The documentation is well-structured, making it easy to find the information \\nyou need. It covers various aspects of the framework, from basic concepts to advanced \\nfeatures.\\nAutogen has documentation with numerous examples and tutorials. The documentation \\ncovers various aspects of the framework, making it accessible to beginners and advanced \\nusers alike. It includes detailed explanations of key concepts and features.\\nCrewAI provides detailed documentation, including how-to guides and examples. The \\ndocumentation is designed to help you get started quickly and understand the framework’s \\ncore concepts. It includes practical examples and step-by-step instructions.\\nWinner: All frameworks have excellent documentation, but it’s easy to find more examples \\nof LangGraph and CrewAI.\\nDo They Provide Multi-Agent Support? \\nMulti-agent support is crucial when you’re dealing with complex applications that involve \\nvarious interaction patterns among multiple agents. This includes: \\n• Hierarchical\\n• Sequential\\n• Dynamic interactions\\nWhen agents are grouped by tools and responsibilities, they tend to perform better \\nbecause focusing on a specific task typically yields better results than when an agent'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 34, 'page_label': '35'}, page_content='35\\nMastering AI Agents\\nmust choose from many tools. Giving each prompt its own set of instructions and few-\\nshot examples can further boost performance. Imagine each agent powered by its own \\nfinely-tuned large language model—this provides a practical framework for development, \\nallowing you to evaluate and improve each agent individually without affecting the broader \\napplication.\\nLangGraph supports various multi-agent patterns, including hierarchical and dynamic \\ngroup chats. It lets you easily define complex interaction patterns between agents. Its \\ngraph-based approach aids in visualizing and managing these interactions effectively. In \\nLangGraph, you explicitly define different agents and their transition probabilities as nodes \\nin a graph. This method gives you extensive control over constructing complex workflows, \\nwhich is essential for managing transition probabilities between nodes.\\nAutogen emerged as one of the first multi-agent frameworks, framing workflows more as \\n“conversations” between agents. This conversational model adds flexibility, allowing you \\nto define how agents interact in various patterns, including sequential and nested chats. \\nAutogen’s design simplifies the management of these complex multi-agent interactions, \\nenabling effective collaboration among agents.\\nCrewAI supports role-based interactions and autonomous delegation among agents. It \\nfacilitates processes like sequential and hierarchical task execution, which are critical for \\nefficiently managing multi-agent interactions. This setup ensures that agents can work \\ntogether seamlessly to achieve common goals. CrewAI provides a higher-level approach \\nthan LangGraph, focusing on creating cohesive multi-agent “teams.”\\nWinner: LangGraph has an edge due to its graph-based approach, which makes it easier \\nto visualize and manage complex interactions.\\nWhat About Caching? \\nCaching is critical for enhancing agent performance by reducing latency and resource \\nconsumption. It does this by storing and reusing previously computed results, which can \\nsignificantly speed up operations.\\nLangGraph supports caching through its built-in persistence layer. This allows you to save \\nand resume graph execution at any point. The caching mechanism ensures that previously \\ncomputed results can be reused, improving performance as well.\\nAutoGen supports caching API requests so they can be reused when the same request is \\nissued.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 35, 'page_label': '36'}, page_content='36\\nMastering AI Agents\\nAll tools in CrewAI support caching, which enables agents to reuse previously obtained \\nresults efficiently. This reduces the load on external resources and speeds up the execution \\ntime. The cache_function attribute of the tool allows you to define finer control over the \\ncaching mechanism.\\nWinner: All frameworks support caching, but LangGraph and CrewAI might have an edge.\\nLooking at the Replay Functionality \\nReplay functionality allows you to revisit and analyze previous interactions, which is useful \\nfor debugging and improving agent performance. This helps you understand the decision-\\nmaking process and identify areas for improvement.\\nLangGraph enhances your debugging and experimentation capabilities with its time travel \\nfeature. This allows you to rewind and explore different scenarios easily. It provides a \\ndetailed history of interactions, enabling thorough analysis and understanding of each step \\nin your process.\\nWhile Autogen does not offer an explicit replay feature, it does allow you to manually \\nupdate the state to control the agent’s trajectory. This workaround provides some level of \\nreplay functionality, but it requires more hands-on intervention from you.\\nCrewAI provides the ability to replay from a task specified from the latest crew kickoff. \\nCurrently, only the latest kickoff is supported, and it will only allow you to replay from the \\nmost recent crew run.\\nWinner: LangGraph and CrewAI make it easy to replay with inbuilt capabilities.\\nWhat About Code Execution? \\nCode execution capabilities enable agents to perform complex tasks by writing and \\nexecuting code. This is particularly useful for tasks that require dynamic calculations or \\ninteractions with external systems.\\nLangGraph integrates with LangChain to support code execution within its workflows. \\nYou can define nodes specifically for executing code, which becomes part of the'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 36, 'page_label': '37'}, page_content='37\\nMastering AI Agents\\noverall workflow. This integration means you can seamlessly incorporate complex code \\nexecutions into your projects.\\nAutogen supports code execution through its built-in code executors. Agents can write \\nand execute code to perform tasks autonomously. The framework provides a safe \\nenvironment for code execution, ensuring that agents can perform tasks securely.\\nCrewAI supports code execution through customizable tools. You can define tools that \\nexecute code and integrate them into the agent’s workflow. This provides flexibility in \\ndefining the capabilities of agents and allows for dynamic task execution.\\nWinner: Autogen might have a slight edge due to its built-in code executors, but the other \\ntwo are also capable.\\nHuman in the Loop Support? \\nHuman-in-the-loop interactions allow agents to receive human guidance and feedback, \\nimproving their performance and reliability. This is particularly important for tasks that \\nrequire human judgment or intervention.\\nLangGraph supports human-in-the-loop interactions through its interruption features. You \\ncan pause the graph execution to provide feedback or make adjustments.\\nAutogen supports human-in-the-loop interactions through its three modes: NEVER, \\nTERMINATE, and ALWAYS.\\nCrewAI supports human-in-the-loop interactions by allowing agents to request human \\ninput during task execution by setting the human_input flag in the task definition. When \\nenabled, the agent prompts the user for input before delivering its final answer.\\nWinner: All frameworks support humans in the loop in different ways.\\nHow Well Do They Accommodate Customization? \\nCustomization options determine how easily you can tailor the framework to your specific \\nneeds and requirements. This includes the ability to define custom workflows, tools, and \\ninteractions.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 37, 'page_label': '38'}, page_content='38\\nMastering AI Agents\\nLangGraph provides fine-grained control over the flow and state of the application. You \\ncan customize the behavior of nodes and edges to suit specific needs. The framework’s \\ngraph-based approach also makes it easy to define complex workflows.\\nAutogen is customizable, allowing users to extend agents with additional components and \\ndefine custom workflows. The framework is designed to be modular and easy to maintain.\\nCrewAI offers extensive customization options, including role-based agent design and \\ncustomizable tools.\\nWinner: All the frameworks provide customization, but the mileage might vary.\\nHow Good Are They At Scaling? \\nScalability is a must to ensure that the framework can grow alongside your requirements. \\nThe framework should sustain its performance and reliability as you incorporate more \\nagents, tools, and interactions. We have no winners here. All three frameworks offer the \\nflexibility to scale the system by adding agents, tools, and customizations according to \\nyour needs.\\nWinner: It remains unclear which framework scales more effectively as more elements are \\nadded. We recommend experimenting with them to get a better idea.\\nLet’s Compare Them All\\nWell, that’s a lot of information to process at once! Refer to the table below (Table 2.2) for a \\nquick overview of what we discussed in this chapter. \\nLangGraph excels \\nin scenarios where \\nworkflows can be \\nrepresented as graphs\\nTo sum it up: \\nAutogen is ideal \\nfor conversational \\nworkflows\\nCrewAI is designed \\nfor role-based multi-\\nagent interactions'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 38, 'page_label': '39'}, page_content='39\\nMastering AI Agents\\nCriteria LangGraph Autogen CrewAI Final Verdict\\nEase of Usage Autogen and CrewAI are more intuitive due to \\ntheir conversational approach and simplicity.\\nMulti-Agent \\nSupport\\nCrewAI excels with its structured role-based \\ndesign and efficient interaction management \\namong multiple agents.\\nTool Coverage LangGraph and CrewAI have a slight edge due \\nto their extensive integration with LangChain.\\nMemory Support\\nLangGraph and CrewAI are advanced in \\nmemory support features, ensuring contextual \\nawareness and learning over time.\\nStructured \\nOutput\\nLangGraph and CrewAI have strong support \\nfor structured outputs that are versatile and \\nintegrable.\\nDocumentation\\nLangGraph and CrewAI offer extensive and \\nwell-structured documentation, making it easier \\nto get started and find examples.\\nMulti-Agent \\nPattern Support\\nLangGraph stands out due to its graph-based \\napproach, which makes it easier to visualize \\nand manage complex interactions.\\nCaching\\nLangGraph and CrewAI lead with \\ncomprehensive caching mechanisms that \\nenhance performance.\\nReplay\\nLangGraph and CrewAI have inbuilt replay \\nfunctionalities, making them suitable for \\nthorough debugging.\\nCode Execution Autogen takes the lead slightly with its innate \\ncode executors, but others are also capable.\\nHuman in the \\nLoop\\nAll frameworks provide effective human \\ninteraction support and are equally strong in this \\ncriterion.\\nCustomization\\nAll the frameworks offer high levels of \\ncustomization, serving various requirements \\neffectively.\\nScalability\\nAll frameworks are capable of scaling effectively, \\nrecommend experimenting with each to \\nunderstand the best fit.\\nOpen source \\nLLMs All frameworks support open-source LLMs.\\nTable 2.2: Overview of comparisons between LangGraph, Autogen, and \\nCrewAI on core features, technical capabilities, and development experience'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 39, 'page_label': '40'}, page_content='40\\nMastering AI Agents\\nPopular Use Cases Centered \\nAround These Frameworks\\nLangGraph \\nChaos Labs has developed the Edge AI Oracle using LangChain and LangGraph for \\nenhanced decision-making in prediction markets. This system utilizes a multi-agent council \\nto ensure accurate, objective, and transparent resolutions. Each agent, ranging from data \\ngatherers to bias analysts and summarizers, plays a role in processing queries through a \\ndecentralized network. This setup effectively reduces single-model biases and allows for \\nconsensus-driven, reliable outputs in high-stakes environments. \\nAutogen\\nBuilt on top of Autogen, OptiGuide employs LLMs to simplify and enhance supply chain \\noperations. It integrates these models to analyze and optimize scenarios efficiently, such \\nas assessing the impact of different supplier choices. The system ensures data privacy \\nand doesn’t transmit proprietary information. Applied within Microsoft’s cloud infrastructure \\nfor server placement, OptiGuide improves operational efficiency and stakeholder \\ncommunication and reduces the need for extensive manual oversight. \\nAll the comparisons aside, here are some interesting use cases and collaborations \\ncentered around LangGraph, Autogen, and CrewAI.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 40, 'page_label': '41'}, page_content='41\\nMastering AI Agents\\nCrewAI \\nWaynabox has transformed travel planning by partnering with CrewAI, offering \\npersonalized, hassle-free travel experiences. This collaboration utilizes CrewAI’s multi-\\nagent system to automatically generate tailored itineraries based on real-time data and \\nindividual preferences. The integration of AI agents—handling activities, preferences, and \\nitinerary customization—allows travelers to enjoy unique adventures without the stress of \\nplanning. This has helped simplify itinerary planning and enhanced Waynabox’s service to \\ncreate a more exciting and seamless travel experience . \\nIn this chapter, we reviewed three frameworks, LangGraph, Autogen, and CrewAI, \\nand how they compare in different aspects, such as ease of use, multi-agent support, \\nand others (See Table 2.2). We also looked at examples of companies that have used \\nthese frameworks in different scenarios and domains to ultimately focus on three \\nfactors: reduction of manual “redundant” work, seamless operations, and productivity \\nimprovement. \\nHowever, it is also imperative to consider the accuracy and reliability of AI agents. This \\ntakes us to the next chapter, where we’ll examine the importance of careful monitoring \\nand feedback to ensure they provide reliable, well-sourced information, necessitating \\nevaluation.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 41, 'page_label': '42'}, page_content='HOW TO \\nEVALUATE AGENTS\\n03 \\nCHAPTER'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 42, 'page_label': '43'}, page_content='43\\nMastering AI Agents\\nHOW TO \\nEVALUATE AGENTS\\nIn the previous chapter, we examined three frameworks, LangGraph, Autogen, and \\nCrewAI, and some interesting use cases related to them.\\nThe next important step in our journey is to understand how we can ensure the accuracy \\nand reliability of AI agents. Why is this important in the first place? \\nEvaluating AI agents is like checking the work of a new employee. You have to make \\nsure they’re doing their job correctly and reliably. Without regular checks and constructive \\nfeedback, it’s tough to trust that the information the agents provide is accurate and helpful.\\nThe best way to understand this is through an example. So, in this chapter, we’re going \\nto build a financial research agent, and we’ll cover how, much like humans, agents can be \\ntaught to solve problems by first understanding the issue, making a plan, taking action, \\nand lastly, evaluating the result. \\nLet’s jump in!'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 43, 'page_label': '44'}, page_content='44\\nMastering AI Agents\\nRequirements \\nYou can install these dependencies in a Python 3.11 environment.\\npip install --quiet -U langgraph==0.2.56 langchain-community==0.3.9 \\nlangchain-openai==0.2.11 tavily-python==0.5.0 promptquality==0.69.1\\nTo do so, sign up on Tavily and OpenAI to generate an API key. Save the keys in a .env file, \\nas shown below.\\nOPENAI_API_KEY=KKK\\nTAVILY_API_KEY=KKK\\nDefining the Problem\\nThis chapter aims to build a financial research agent that “thinks” through and acts on \\nproblems within a financial dataset. We can create a workflow that receives a question, \\nbreaks it down into granular questions, searches the web using Tavily, and analyzes the \\nresults. \\nTo analyze the results, we use the ReAct agent, which works with the Tavily API to think \\nthrough and act on problems.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 44, 'page_label': '45'}, page_content='45\\nMastering AI Agents\\nDefine the ReAct Agent\\nWithin your IDE of choice, you can create a new Jupyter Notebook agent.ipynb.\\nWe can import a prebuilt ReAct agent along with a web search tool called Tavily. While we \\nuse the same agent for all steps in this example, you could use different agents for different \\ntasks. The best part? You can customize it further in later examples. \\nLook at Fig 3.1 to understand this better. This code sets up an AI-driven chat agent \\nnamed Fred, designed to function as a finance expert in 2024. Fred will use specific tools \\nand a planning framework to research and answer questions.\\nFig. 3.1: Setting up the agent'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 45, 'page_label': '46'}, page_content='46\\nMastering AI Agents\\nState Management\\nNow, let’s talk about how our agent keeps track of everything it needs to do. Think of it like \\na smart to-do list system with three main parts.\\nFirst, we need a way to track what the agent plans to do. We’ll use a simple list of steps \\nwritten as text strings. This is like having a checklist of tasks the agent needs to complete.\\nSecond, we want to remember what it has already done and what happened with each \\ntask. For this, we’ll use a list of pairs (or tuples in programming terms). Each pair contains \\nboth the action taken and what resulted from that action. \\nLastly, we need to store two more important pieces of information: the original question that \\nwas asked (the input) and the final answer once the agent finishes its work (the response). \\nThis setup gives our agent everything it needs to function effectively. \\nIn Fig 3.2, the PlanExecute class, a dictionary type, manages an execution process, \\nincluding input, plan steps, previous steps, and a response. The Plan class, using \\nPydantic, defines a structured plan with steps that should be followed in a sorted order.\\nFig. 3.2: Defining structures for managing and executing a sequential plan of actions'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 46, 'page_label': '47'}, page_content='47\\nMastering AI Agents\\nThe planning step is where our agent will begin to tackle a research question. We’ll use a \\nspecial feature called function calling to create this plan. Let’s break down how it works.\\nFirst, we create a template for how our agent should think. We tell it that it’s a finance \\nresearch agent working in October 2024, and its job is to break down big questions into \\nsmaller, manageable steps.\\nThis template, called planner_prompt (See Fig 3.3), gives our agent clear instructions: \\ncreate a simple, step-by-step plan where each step leads logically to the next. Ensure that \\nno steps are missing or unnecessary. The final step should give us our answer.\\nThe code sets this up by using ChatPromptTemplate, which has two main parts:\\n• A system message that explains the agent’s role and how it should plan\\n• A placeholder for the messages we’ll send it\\nFig. 3.3: Guiding the agent to create a step-by-step plan that should lead to the correct \\nanswer for a given objective\\nWe then connect this template to ChatOpenAI using gpt-4o-mini with temperature set to \\n0 for consistent results. We take gpt-4o-mini being low on cost. The “structured output” \\npart means the plan will come out in a specific format we can easily work with.\\nWhen we test it with a real question like “Should we invest in Tesla given the current \\nsituation of EVs?” the agent will create a detailed plan for researching this investment \\ndecision. Each step will help gather the information needed to make an informed \\nrecommendation about Tesla stock based on the current electric vehicle market \\nconditions. (See Fig 3.4)'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 47, 'page_label': '48'}, page_content='48\\nMastering AI Agents\\nThink of it like creating a research roadmap. We’re giving our agent the tools and \\nguidelines it needs to break down complex questions into manageable research tasks.\\nFig. 3.4: Testing the agent with a question\\nThink of re-planning as the agent’s ability to adjust its strategy based on what it has already \\nlearned. This is similar to how we might revise our research approach after discovering \\nnew information. Let’s break down how this works.\\nFirst, we create two types of possible actions the agent can take:\\n• Response: When the agent has enough information to answer the user’s question\\n• Plan: When the agent needs to do more research to get a complete answer\\nThe re-planning prompt is like giving our agent a structured way to think about what to do \\nnext. It looks at three things:\\n• The original question (objective)\\n• The initial plan it made\\n• What steps have already been completed and what was learned\\nUsing this information, the agent can decide to either:\\n• Create new steps to gather more needed information\\n• Give a final answer if it has enough information\\nThe clever part is that the agent won’t repeat steps it’s already done. It focuses only on \\nwhat still needs to be investigated. This makes the research process more efficient and \\nprevents redundant work. It’s like having a research assistant who can intelligently adjust \\ntheir approach based on what they’ve already discovered.\\nThis process helps our agent stay focused and efficient, only pursuing new information \\nwhen needed and knowing when it’s time to provide a final answer to the user.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 48, 'page_label': '49'}, page_content='49\\nMastering AI Agents\\nWe connect this re-planning ability to gpt-4o with the temperature set to 0. By setting the \\ntemperature to 0 (See Fig 3.5), we force the model to generate the same response for the \\nsame input. This helps us in making experiments reproducible.\\nFig. 3.5: Replanner_prompt to review and update a given plan based on past actions'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 49, 'page_label': '50'}, page_content='50\\nMastering AI Agents\\nCreate the Graph\\nThink of this graph as a roadmap that shows how our agent moves from one task to \\nanother. We have three main functions that work together:\\nFig. 3.6: Managing and executing using state-based logic'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 50, 'page_label': '51'}, page_content='51\\nMastering AI Agents\\nThe execute_step function handles individual tasks. It takes the first item from our plan, \\nformats it properly, and has the agent work on it. It’s like giving a specific assignment to a \\nresearch assistant and getting back their findings. The agent keeps track of what it did and \\nwhat it learned.\\nThe plan_step function is where everything begins. When given a question, it creates the \\ninitial research plan. This is like creating a first draft of how to tackle the problem.\\nThe replan_step function is where the agent decides what to do next. After completing a \\ntask, it looks at what it has learned and either:\\n• Creates new steps if more research is needed\\n• Provides a final answer if it has enough information\\nFinally, we have the should_end function, which works like a checkpoint. It checks \\nwhether we have a final answer ready. If we do, it ends the process. If not, it tells the agent \\nto continue working. You can see all these functions in the code snippet below, in Fig 3.6.\\nWe use StateGraph to create a map that guides our agent through its research journey via \\ndifferent actions it can take. Here’s how it flows:\\nFirst, we create the basic structure of the workflow with its three main stops:\\n• A planning station (“planner”)\\n• A research station (“agent”)\\n• A reviewing station (“replan”)\\nThen, we connect these stations in a logical order:\\n1. Everything starts at the planning station\\n2. From planning, the agent moves to doing research\\n3. After research, it goes to reviewing what it learned\\nAt the reviewing station, the agent makes an important decision:\\n• Either continue with more research if needed\\n• Or finish up if it has a complete answer\\nThis creates a smooth cycle in which the agent can continue researching until it has \\neverything it needs to answer the original question. It’s like having an intelligent research \\nassistant who knows when to dig deeper and when they’ve found enough information.\\nFinally, we compile this workflow into something we can easily use, just like any other tool \\nin our system. This makes our research agent ready to tackle real questions and provide \\nthorough, well-researched answers. See Fig 3.7.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 51, 'page_label': '52'}, page_content='52\\nMastering AI Agents\\nFig. 3.7: Creating the structure of the workflow \\nWe can visualize the agent workflow with a mermaid diagram, as shown in Fig 3.8. See the \\noutput in Fig 3.9.\\nFig. 3.8: Visualizing the workflow using Mermaid Chart'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 52, 'page_label': '53'}, page_content='53\\nMastering AI Agents\\n_start_\\nplanner\\nreplan\\n_end_\\nagent\\n_end_tools\\nagent\\n_start_\\nFig. 3.9: Mermaid Chart workflow output'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 53, 'page_label': '54'}, page_content='54\\nMastering AI Agents\\nCreate the LLM Judge\\nNext, we create a LLM judge to evaluate our agent’s performance. This ensures our \\nagents’ responses adhere to the given context and maintain relevance and accuracy. \\nThe inbuilt scorers make it very easy to set up one for us. We use gpt-4o as our LLM for \\nthe context adherence metric, with three evaluations per response for better to ensure \\ngreat evaluation accuracy. This scorer specifically looks at how well the agent sticks to the \\ncontext and provides relevant information. \\nNote that we’re using GPT-4o to evaluate a smaller AI model, which is like having an expert \\noversee a novice’s work. GPT-4o, with its advanced capabilities and deep understanding \\nof language nuances, can be a reliable benchmark for judging the smaller model’s (in our \\ncase, the 4o-mini) responses. See Fig 3.10.\\nFig. 3.10: Implementing the LLM as Judge functionality \\nWe then set up a Galileo evaluation callback that will track and record our agent’s \\nperformance. It’s like having a quality control system that monitors our research process. \\nNext, we set some basic config for our agent:\\n• It can’t go through more than 30 cycles (recursion_limit).\\n• It must use our evaluation system (callbacks).'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 54, 'page_label': '55'}, page_content='55\\nMastering AI Agents\\nUse Galileo Callbacks\\nYou’ll observe in Fig 3.11 that we’re using the Galileo callback, GalileoPromptCallback, \\nwhich is used to log the execution of chains in applications like Langchain.\\nWith just two lines of code, we can get all the information needed to visualize and debug \\nthe traces. \\nFig. 3.11: Galileo Callback\\nWe then run our agent with a specific test question. The system will process this question \\nthrough the research workflow we built earlier.\\nThe code is set up to show us what’s happening at each step (that’s what the async for \\nloop does). It will print out each action and result as they happen, letting us watch the \\nresearch process in real-time.\\nFinally, we close our evaluation session with evaluate_handler.finish(). This saves all the \\nperformance data we collected during the run to the Galileo Evaluate console so we can \\nsee the chain visualization and the agent metrics. See Fig 3.12 and Fig 3.13. \\nFig. 3.12: Closing the evaluation session'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 55, 'page_label': '56'}, page_content='56\\nMastering AI Agents\\nFig. 3.13: Chain visualization \\nYou can run several experiments to evaluate the research agent’s performance. For \\ninstance, you can use the project dashboard to see how different test runs performed \\nbased on key metrics (see Figure 3.14).\\nThe standout performer was test-3, which earned the top rank with impressive results. \\nPerformance of test-3:\\n• Context Adherence Score: 0.844 (High relevance to the research questions)\\n• Speed: Completed tasks in 84,039 milliseconds (Fastest among all tests)\\n• Responses Processed: 3 during the run\\n• Cost: $0.0025 per run (Low cost)\\nOverall Test Performances:\\n• Response Time Range: From 134,000 to 228,000 milliseconds\\n• Context Adherence Score Range: From 0.501 to 0.855\\n• Number of Responses: Ranged from 1 to 7 per test\\n• Cost Efficiency: Remained consistent across all runs, between $0.002 and $0.004 per \\nrun\\nThese results give valuable insights into our agent’s capabilities and help identify the most \\neffective configuration for future research tasks.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 56, 'page_label': '57'}, page_content='57\\nMastering AI Agents\\nFig. 3.14: Galileo’s dashboard that shows multiple runs\\nNow, you can go inside each test run to see agent executions (See Fig 3.15). The \\ndashboard reveals seven different research queries that our agent processed. Each query \\nfocused on analyzing different companies’ financial metrics. Here’s what you’ll observe:\\n• The agent shows varying performance across different samples\\n• There’s an alert noting that six samples had latency greater than 10 seconds, which \\nsuggests room for optimization. \\n• Average Latency for run: 210,623 ms\\n• Average Cost for run: $0.004 per execution\\nThis detailed view helps you understand where the agent performs well and where it might \\nneed improvements in terms of speed and accuracy.\\nFig. 3.15: Detailed view for each test run'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 57, 'page_label': '58'}, page_content='58\\nMastering AI Agents\\nLooking at the trace view (Fig 3.16), you can see a detailed breakdown of an execution \\nchain where the context adherence was notably low at 33.33%. The system explanation \\nhelps us understand why:\\n“The response has a 33.33% chance of being consistent with the context. Based on the \\nanalysis, while some of the figures like those for later 2022 and 2023 are supported by \\ndocument references (such as Q3 2023 and Q4 2023), many earlier quarters’ figures \\nlack direct evidence from the documents or explicit mentions, leading to incomplete \\nsupport for claims.”\\nFig. 3.16: Detailed breakdown of an execution chain to help with evaluation'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 58, 'page_label': '59'}, page_content='59\\nMastering AI Agents\\nThis reveals two key issues in our agent’s performance:\\nTo improve this, there are two possible main paths:\\n1. Improve the retrieval system:\\n• Make sure we’re gathering sufficient historical data.\\n• Expand the search scope to include earlier quarterly reports.\\n• Better source verification for historical data.\\n2. Enhance the prompts:\\n• Add explicit instructions to cite sources for all numerical claims.\\n• Include requirements to clearly distinguish between verified and unverified data.\\n• Add checks for data completeness before making comparisons.\\nLet’s take a quick look at what we learned in the chapter. We saw how our agent \\nimplemented the ReAct (Reasoning and Acting) framework to:\\n• Break down complex questions into smaller steps\\n• Plan and execute research tasks systematically\\n• Re-evaluate and adjust its approach based on findings\\nWe also explored the evaluation process using:\\n• An LLM judge (GPT-4) to assess response quality\\n• Metrics like context adherence, speed, and cost efficiency\\n• Galileo’s evaluation dashboard for performance tracking\\nThat said, testing the finance research agent in this chapter teaches you something \\nvery important and valuable: an AI is only as good as our ability to check its work. By \\nlooking closely at how the agent performed, you could see exactly what it did well (like \\nfinding recent data quickly) and what it struggled with (like backing up older numbers \\nwith proper sources). The evaluation step helped spot these issues easily, showing us \\nwhere to improve the agent.\\nThe next chapter is going to get even more interesting (plus, you have five solid use \\ncases to look at!) as we explore different metrics to evaluate the AI agents across four \\ndimensions: System Metrics, Task Completion, Quality Control, and Tool interaction.\\nThe agent is citing recent data \\n(2022-2023) correctly with \\nproper sources.\\nHowever, it’s making claims \\nabout earlier data without proper \\ndocumentation or references.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 59, 'page_label': '60'}, page_content='METRICS FOR \\nEVALUATING AI \\nAGENTS\\n04 \\nCHAPTER'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 60, 'page_label': '61'}, page_content='61\\nMastering AI Agents\\nBefore we explore metrics for evaluating AI, let’s recall our key insights into agent \\nevaluation. Using LLM-based judges (like GPT-4o) and robust metrics (such as context \\nadherence), we effectively measured an agent’s performance across various dimensions, \\nincluding accuracy, speed, and cost efficiency. We then set up Galileo’s evaluation callback \\nto track and record the agent’s performance. \\nThis next chapter will explore various metrics for evaluating AI agents using five solid case \\nstudies.\\nLet’s consider a document processing agent. While it might initially demonstrate strong \\nperformance metrics, we may have to probe into several questions:\\n• Is it maintaining optimal processing speeds and resource usage?\\n• How consistently does it complete assigned tasks without human intervention?\\n• Does it reliably adhere to specified formatting and accuracy requirements?\\n• Is it selecting and applying the most appropriate tools for each task?\\nThrough a series of hypothetical case studies, we’ll explore how organizations may \\ntransform their AI agents into reliable digital colleagues using key metrics. These examples \\nwill demonstrate practical approaches to:\\n• Improving task completion rates and reducing human oversight\\n• Enhancing output quality and consistency\\n• Maximizing effective tool utilization and selection\\nMetrics for \\nEvaluating AI Agents'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 61, 'page_label': '62'}, page_content='62\\nMastering AI Agents\\nYou should remember that the goal isn’t perfection but establishing reliable, measurable, \\nand continuously improving AI agents that deliver consistent value across all four key \\nperformance dimensions. See Fig 4.1\\nFig 4.1: Four key performance dimensions to evaluate AI agents'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 62, 'page_label': '63'}, page_content='63\\nMastering AI Agents\\nAuto Pay Manual Check Appeal Queue\\nCase Study 1:\\nAdvancing the Claims \\nProcessing Agent\\nFig 4.2: An overview of the Claims Processing System \\nValidate\\nReview\\nValidate\\nVerify\\nProcess\\nClaim Validator\\nCoverage Check\\nMedical Claims Provider info Patient History\\nNetwork Check Eligibility Check\\nPayment Calculator\\nClaim Processing System Overview\\nClaim Decision\\nValidate\\nValidate\\nClear Review Needed Denied'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 63, 'page_label': '64'}, page_content='64\\nMastering AI Agents\\nA healthcare network implemented an AI agent to automate insurance claims processing, \\naiming to enhance efficiency and accuracy. However, this initiative inadvertently introduced \\ncompliance risks, highlighted by several key issues:\\n• The AI agent struggled with complex claims, leading to payment delays and provider \\nfrustration. Because of the inconsistency in handling these claims, claims processors \\nspent more time verifying the AI’s work than processing new claims.\\n• The error rate in complex cases raised alarms with the compliance team, especially \\ncritical given the stringent regulatory demands of healthcare claims processing.\\nFunctionality\\nThe AI was designed to:\\n• Analyze medical codes\\n• Verify insurance coverage\\n• Check policy compliance\\n• Validate provider information\\n• Automatically assess claim completeness and compliance\\n• Calculate expected payments and generate preliminary approvals for straightforward \\nclaims\\nChallenges\\nTo counter these issues, the network focused on three key performance indicators to \\ntransform their AI agent’s capabilities:\\n1. LLM Call Error Rate\\n• Problem: API failures during claims analysis led to incomplete processing and \\nincorrect approvals.\\n• Solution: Implementing robust error recovery protocols and strict state \\nmanagement ensured accurate rollbacks and reprocessing.\\n2. Task Completion Rate\\n• Problem: The agent incorrectly marked claims as ‘complete’ without conducting \\nall necessary verifications.\\n• Solution: Mandatory verification checklists and completion criteria were introduced \\nto meet all regulatory requirements before finalizing claims.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 64, 'page_label': '65'}, page_content='65\\nMastering AI Agents\\n3. Number of Human Requests\\n• Problem: The agent took on complex cases beyond its capability, such as \\nexperimental procedures or cases requiring coordination of benefits across multiple \\npolicies.\\n• Solution: Stricter escalation protocols automatically route high-risk cases to \\nhuman experts based on claim complexity and regulatory requirements.\\n4. Token Usage per Interaction\\n• Problem: Unnecessary inclusion of patient details in processing routine claims \\nheightened privacy risks.\\n• Solution: Strict data minimization protocols and context-cleaning practices were \\nadopted to ensure that only essential protected health information is used\\nOutcomes\\nThe enhanced agent delivered:\\n• Faster claims processing\\n• Higher compliance accuracy\\n• Improved resource utilization\\n• Reduced rejection rates'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 65, 'page_label': '66'}, page_content='66\\nMastering AI Agents\\nCase Study 2:\\nOptimizing the Tax Audit Agent\\nFig 4.3: An overview of the Tax Auditing System\\nApprove\\nDeep Scan Standard Check\\nDocument Hub\\nFinancial Records\\nDocumentation Phase\\nReceiptsTax Returns\\nAudit Queue\\nQuick Review\\nTax Audit System Overview\\nFinal \\nAssessment\\nRisk Detection\\nAI Engine\\nPass\\nHigh Risk\\nUpload\\nMedium Risk\\nUpload\\nFeed\\nAnalysis Phase\\nIssue\\nLow Risk\\nUpload'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 66, 'page_label': '67'}, page_content='67\\nMastering AI Agents\\nAt a mid-sized accounting firm, their deployed AI audit agent created unexpected \\nworkflow bottlenecks. While the agent effectively handled routine tax document \\nprocessing, the firm was concerned about three critical issues:\\n• Lengthy turnaround times for complex corporate audits\\n• Excessive computing costs from inefficient processing\\n• A growing backlog of partially completed audits requiring manual review\\nWhat should have streamlined their operations was instead causing senior auditors to \\nspend more time supervising the AI’s work than doing their specialized analysis. The firm \\nneeded to understand why its significant investment in AI wasn’t delivering the anticipated \\nproductivity gains.\\nFunctionality\\nThe AI audit agent was designed to:\\n• Process various tax documents, from basic expense receipts to complex corporate \\nfinancial statements.\\n• Automatically extract and cross-reference key financial data in corporate tax returns.\\n• Systematically verify compliance across multiple tax years.\\n• Validate deduction claims against established rules and flag discrepancies for review.\\n• For simpler cases, it could generate preliminary audit findings and reports.\\n• The system was integrated with the firm’s tax software and document management \\nsystems to access historical records and precedents.\\nChallenges\\nThe team focused on three critical metrics to reshape their agent’s capabilities:\\n1. Tool Success Rate\\n• Problem: The agent struggled with document processing efficiency, especially with \\ncomplex document hierarchies.\\n• Solution: Implementation of structured document classification protocols and \\nvalidation frameworks improved handling of complex documents.\\n2. Context Window Utilization\\n• Problem: The agent’s processing of tax histories in their entirety was suboptimal, \\noften missing connections between related transactions.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 67, 'page_label': '68'}, page_content='68\\nMastering AI Agents\\n• Solution: Smart context segmentation was introduced, allowing the agent to \\nfocus on relevant time periods and maintain historical context. This enhanced the \\ndetection of subtle tax patterns.\\n3. Steps per Task\\n• Problem: The agent applied the same level of analysis intensity to all tasks, \\nregardless of complexity.\\n• Solution: Adaptive workflows were implemented to adjust analytical depth based \\non the complexity of the task.\\nOutcomes\\nThe refined capabilities of the AI agent led to:\\n• Decreased audit completion times\\n• Improved accuracy in discrepancy detection\\n• More efficient utilization of processing resources'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 68, 'page_label': '69'}, page_content='69\\nMastering AI Agents\\nCase Study 3: \\nElevating the Stock Analysis Agent\\nFig 4.4: An overview of the Stock Analysis System\\nWatch ListPriority Trade Exit Position\\nIntegrate\\nExtract\\nIntegrate\\nProcess\\nAnalyze\\nMarket Context\\nTechnical \\nIndicators\\nPrice Data News Feed\\nMarket Data\\nFinancial Reports\\nSentiment\\nAnalysis\\nFundamental\\nMetrics\\nPrediction Engine\\nStock Analysis System Overview\\nTrading Signals\\nIntegrate\\nCollect\\nStrong Buy Hold Sell'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 69, 'page_label': '70'}, page_content='70\\nMastering AI Agents\\nAt a boutique investment firm, their AI-enhanced analysis service was under scrutiny as \\nclients questioned its value. Portfolio managers were overwhelmed by redundant analysis \\nrequests and faced inconsistent reporting formats across client segments. \\nThis situation undermined the firm’s competitive edge of providing rapid market insights \\nas analysts spent excessive time reformatting and verifying the AI’s outputs. The inability \\nof the AI to adjust its analysis depth based on varying market conditions resulted in either \\noverly superficial or unnecessarily detailed reports, compromising client confidence in the \\nservice.\\nFunctionality\\nThe AI analysis agent was developed to:\\n• Process multiple data streams, including market prices, company financials, news \\nfeeds, and analyst reports.\\n• Generate comprehensive stock analyses by evaluating technical indicators, assessing \\nfundamental metrics, and identifying market trends across different timeframes.\\n• Generate customized reports combining quantitative data with qualitative insights for \\neach analysis request.\\n• The system was integrated with the firm’s trading platforms and research databases, \\nproviding real-time market intelligence.\\nChallenges\\nThrough analyzing three crucial metrics, the team improved the AI agent’s performance:\\n1. Total Task Completion Time\\n• Problem: The agent applied a uniform analysis depth across all stock types, \\nregardless of their complexity.\\n• Solution: Adaptive analysis frameworks based on stock characteristics were \\nimplemented to improve processing efficiency while maintaining insight quality.\\n2. Output Format Success Rate\\n• Problem: Inconsistencies in how the agent presented market analysis for different \\nuser roles. Analysts and business managers received inappropriate levels of detail \\nfor their specific needs.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 70, 'page_label': '71'}, page_content='71\\nMastering AI Agents\\n• Solution: Role-specific output templates and better parsing of output requirements \\nwere introduced, enabling the agent to format its analyses appropriately for different \\naudiences while maintaining analytical accuracy.\\n3. Token Usage per Interaction\\n• Problem: The agent inefficiently reprocessed entire documents for new queries, \\nsuch as analyzing a company’s quarterly earnings report multiple times for related \\nquestions.\\n• Solution: Improved memory management and progressive analysis techniques \\nwere adopted, allowing the agent to reuse relevant insights across related queries \\nwhile ensuring analytical precision.\\nOutcomes\\nThe enhancements to the AI agent delivered:\\n• More precise market analysis\\n• Faster processing times\\n• Improved resource utilization'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 71, 'page_label': '72'}, page_content='72\\nMastering AI Agents\\nCase Study 4: \\nUpgrading the\\nCoding Agent\\nFig 4.5: An overview of the Development Assistant System\\nDev CheckAuto Apply Team Review\\nProcess\\nParse\\nProcess\\nReview\\nGenerate\\nMarket Context\\nSyntax Check\\nNew Code Git History\\nCode Analysis\\nDoc Strings\\nPattern Analysis Context Building\\nSuggestion Engine\\nDevelopment Assistant System Overview\\nCode Review\\nProcess\\nScan\\nOptimal Needs Review Complex'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 72, 'page_label': '73'}, page_content='73\\nMastering AI Agents\\nA software development company implemented an AI coding assistant to enhance \\nengineering productivity. However, rather than speeding up development cycles, the \\nassistant became a source of frustration due to frequent disruptions and unreliable \\nperformance, especially during critical sprint deadlines. \\nDevelopers experienced delays as the agent struggled with large codebases and provided \\nirrelevant suggestions that failed to consider project-specific requirements. Additionally, \\nrising infrastructure costs from inefficient resource usage further exacerbated the situation, \\nprompting a need for transformative improvements to make the AI assistant a genuine \\nproductivity tool.\\nFunctionality\\nThe AI coding assistant was designed to:\\n• Analyze codebases to provide contextual suggestions, identify potential bugs, and \\nrecommend optimizations.\\n• Review code changes, ensuring compliance with project standards and generating \\ndocumentation suggestions.\\n• Handle multiple programming languages and frameworks, adapting recommendations \\nto specific project needs.\\n• The system integrated with common development tools and version control systems, \\nsupporting developers throughout the development cycle.\\nChallenges\\nBy optimizing three pivotal indicators, the team significantly enhanced the agent’s \\ncapabilities:\\n1. LLM Call Error Rate\\n• Problem: Frequent API timeouts when processing large code files and connection \\nfailures during peak usage.\\n• Solution: Robust error handling, automatic retries, and request queuing \\nmechanisms were implemented, greatly enhancing API call reliability and minimizing \\nworkflow disruptions.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 73, 'page_label': '74'}, page_content='74\\nMastering AI Agents\\n2. Task Success Rate\\n• Problem: Inconsistencies in the relevance and completeness of code suggestions. \\nThe agent sometimes provided overly complex rewrites for simple style fixes or \\ninadequate details for required refactoring.\\n• Solution: Standardized response templates for various code issues, including style \\nguides, bug fixes, refactoring suggestions, and optimization recommendations, \\nwere introduced, making the agent’s suggestions more consistently actionable.\\n3. Cost per Task Completion\\n• Problem: Inefficient resource allocation in debugging workflows, using the same \\ncomputational power for minor and major tasks.\\n• Solution: Tiered processing was implemented based on the complexity and scope \\nof code changes, optimizing resource usage while maintaining high analysis quality.\\nOutcomes\\nThe optimizations delivered:\\n• Enhanced code analysis accuracy\\n• Improved suggestion relevance\\n• More efficient resource utilization'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 74, 'page_label': '75'}, page_content='75\\nMastering AI Agents\\nCase Study 5: \\nEnhancing the Lead \\nScoring Agent\\nFig 4.6: An overview of the Lead Scoring System\\nNurture TrackSales Ready Keep Warm\\nCombine\\nParse\\nCombine\\nReview\\nFeed\\nSignal Processor\\nBehavior Score\\nWebsite Visits Email Opens\\nDigital Signals\\nSocial Clicks\\nInterest Score Engagement \\nScore\\nML Engine\\nLead Scoring System Overview\\nLead \\nQualification\\nCombine\\nScan\\nStrong Signals Medium Signals Weak Signals'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 75, 'page_label': '76'}, page_content='76\\nMastering AI Agents\\nA software development company implemented an AI lead scoring agent to optimize sales \\nstrategies. Despite the promise of enhancing lead qualification efficiency, the agent was \\ninitially ineffective, leading to misclassification of prospects and declining conversion rates. \\nSales representatives found themselves pursuing low-potential leads due to outdated or \\ninaccurate scores, especially during peak times, which resulted in increased costs per \\nqualified lead and compromised growth targets.\\nFunctionality\\n• Evaluate data from multiple sources like website interactions, email responses, social \\nmedia engagement, and CRM records to assess potential customers.\\n• Analyze company profiles, assess engagement patterns, and generate lead scores \\nbased on predefined criteria.\\n• Automatically categorize prospects by industry, company size, and potential deal value, \\nupdating scores in real-time as new information became available.\\n• Integrate with the company’s sales tools, providing sales representatives with prioritized \\nlead lists and engagement recommendations.\\nChallenges\\n1. Token Usage per Interaction\\n• Problem: The agent repetitively generated new analyses for similar company \\nprofiles instead of leveraging existing insights.\\n• Solution: Implementation of intelligent pattern matching and context reuse \\nimproved processing efficiency while maintaining lead quality assessment accuracy.\\n2. Latency per Tool Call\\n• Problem: Performance bottlenecks arose from sequential database querying \\npatterns, causing delays.\\n• Solution: Introduction of parallel processing and smart data caching transformed \\nthe agent’s analysis speed.\\n3. Tool Selection Accuracy\\n• Problem: The agent inefficiently selected between similar analysis methods, using \\nmore computationally expensive tools for basic tasks.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 76, 'page_label': '77'}, page_content='77\\nMastering AI Agents\\n• Solution: Developing smarter selection criteria allowed the agent to match tool \\ncomplexity with the analysis needs, using simpler tools for straightforward tasks \\nand reserving intensive tools for complex cases.\\nOutcomes\\n• Faster prospect analysis processing\\n• Higher lead qualification accuracy\\n• Improved resource utilization efficiency\\nThese use cases reveal a crucial truth: effective AI agents require careful \\nmeasurement and continuous optimization. As these systems become more \\nsophisticated, the ability to measure and improve their performance becomes increasingly \\nimportant.\\nHere’s a quick takeaway: \\n• Metric-driven optimization must align with business objectives\\n• Human workforce transformation is crucial for AI success\\n• Clear outcome targets drive better optimization decisions\\n• Regular measurement and adjustment cycles are essential\\n• Balance between automation and human oversight is critical'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 77, 'page_label': '78'}, page_content='WHY MOST\\nAI AGENTS FAIL\\n& HOW TO FIX THEM\\n05 \\nCHAPTER'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 78, 'page_label': '79'}, page_content='79\\nMastering AI Agents\\nCHAPTER 5\\nWHY MOST AI AGENTS FAIL \\n& HOW TO FIX THEM\\nIn the previous chapter, we looked at different metrics for evaluating our AI agents, namely \\nalong four core dimensions: Technical efficiency, Task Completion, Quality Control, and \\nTool interaction. In our journey, we’ve also seen how agents are powerful tools capable of \\nautomating complex tasks and processes with many frameworks that make it possible to \\nbuild complex agents in a few lines of code. However, many AI agents fail to deliver the \\nexpected outcomes despite their potential.\\nIn this chapter, we’ll examine why agents fail, providing insights into common pitfalls and \\nstrategies to overcome them.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 79, 'page_label': '80'}, page_content='80\\nMastering AI Agents\\nPoorly Defined Prompts\\n• Define Clear \\nObjectives\\n• Craft Detailed \\nPersonas\\n• Use Effective \\nPrompting \\nEvaluation Challenges\\n• Continuous \\nEvaluation\\n• Use Real-World \\nScenarios\\n• Incorporate \\nFeedback Loops\\nDifficult to Steer\\n• Specialized Prompts\\n• Hierarchical Design\\n• Fine-Tuning Models\\nHigh Cost of Running\\n• Reduce Context Size\\n• Use Smaller Models\\n• Cloud-Based Solutions\\nPlanning Failures\\n• Task Decomposition\\n• Multi-Plan Selection\\n• Reflection and \\nRefinement\\nReasoning Failures\\n• Enhance Reasoning \\nCapabilities\\n• Fine-Tune LLMs with \\nFeedback\\n• Use Specialized Agents\\nTool Calling Failures\\n• Define Clear Parameters\\n• Validate Tool Outputs\\n• Tool Selectio \\nVerificationLoops\\nGuardrails\\n• Rule-Based Filters & \\nValidation\\n• Human-in-the-Loop \\nOversight\\n• Ethical & Compliance \\nFrameworks\\nAgent Scaling\\n• Scalable Architectures\\n• Resource Management\\n• Monitor Performance\\nFault Tolerance\\n• Redundancy\\n• Automated Recovery\\n• Stateful Recovery\\nInfinite Looping\\n• Clear Termination \\nConditions\\n• Enhance Reasoning & \\nPlanning\\n• Monitor Agent Behavior\\nDEVELOPMENT \\nISSUES\\nLLM \\nISSUES\\nPRODUCTION \\nISSUES\\nAI Agent Challenges and Solutions'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 80, 'page_label': '81'}, page_content='81\\nMastering AI Agents\\nDevelopment Issues\\nPoorly Defined Task\\nor Persona\\nA well-defined task or persona is \\nessential for effectively operating your AI \\nagents. It clarifies the agent›s objectives, \\nconstraints, and expected outcomes, \\nensuring that your agent can make \\nappropriate decisions and perform \\neffectively. Without it, agents may \\nstruggle to make appropriate decisions, \\nleading to suboptimal performance.\\nDefine Clear Objectives\\nYou should specify the goals, \\nconstraints, and expected outcomes for \\neach agent.\\nCraft Detailed Personas\\nDevelop personas that outline the \\nagents role, responsibilities, and \\nbehavior for you.\\nPrompting\\nUse research-backed prompting \\ntechniques to reduce hallucinations for \\nyour agents.\\nEvaluation\\nIssues\\nEvaluation helps you identify weaknesses \\nand ensures your agents operate reliably \\nin dynamic environments. However, \\nevaluating agents› performance is \\ninherently challenging. Unlike traditional \\nsoftware, where outputs can be easily \\nvalidated against expected results, agents \\noperate in dynamic environments with \\ncomplex interactions, making it difficult for \\nyou to establish clear metrics for success.\\nContinuous Evaluation\\nImplement an ongoing evaluation system \\nto assess your agents performance and \\nidentify areas for improvement.\\nUse Real-World Scenarios\\nTest your agents in real-world scenarios to \\nunderstand their performance in dynamic \\nenvironments.\\nFeedback Loops\\nIncorporate feedback loops to allow \\nfor continuous improvement based on \\nperformance data.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 81, 'page_label': '82'}, page_content='82\\nMastering AI Agents\\nTask \\nBreakdown\\nTask \\nImplementation\\nResource \\nAllocation\\nQuality \\nControl\\nLLM Issues\\nYou can steer LLMs towards specific \\ntasks or goals for consistent and reliable \\nperformance. Effective steering ensures \\nthat agents can perform their intended \\nfunctions accurately and efficiently. LLMs \\nare influenced by vast amounts of training \\ndata, which can lead to unpredictable \\nbehavior, and fine-tuning them for specific \\ntasks requires significant expertise and \\ncomputational resources.\\nSpecialized Prompts\\nUse specialized prompts to guide the LLM \\ntoward specific tasks.\\nHierarchical Design\\nImplement a hierarchical design where \\nspecialized agents handle specific tasks, \\nreducing the complexity of steering a \\nsingle agent. (See Fig 5.1)\\nFine-Tuning\\nContinuously fine-tune the LLM based \\non task-specific data to improve \\nperformance. \\nFig 5.1: Hierarchical design with specialized agents performing specific tasks\\nController Agent\\nPlanning Agent Research Agent Execution Agent\\nData \\nCollection Analysis\\nDifficult to Steer\\nMastering AI Agents'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 82, 'page_label': '83'}, page_content='83\\nMastering AI Agents\\nHigh Cost of Running\\nRunning LLMs, especially in production \\nenvironments, can be prohibitively \\nexpensive. The computational resources \\nrequired for inference, particularly \\nfor large models, can lead to high \\noperational costs. This makes it difficult \\nfor organizations to scale their agent \\ndeployments cost-effectively.\\nReduce Context\\nAgents can run for a while in their \\niterative loops. Introduce mechanisms to \\nuse as low context as possible to reduce \\nthe tokens.\\nUse Smaller Models\\nWhere possible, use smaller models or \\ndistill larger models to reduce costs.\\nCloud Solutions\\nUse cloud-based solutions to manage \\nand scale computational resources \\nefficiently. Design a serverless system to \\nsave wasting of resources. (See Fig 5.2.)\\nComponents of Fig 5.2\\n• The SQS Queue acts as our request buffer.\\n• The Lambda Controller makes intelligent decisions about request handling. \\n• Small Model API for simple completions and basic tasks\\n• Medium Model API for moderate complexity tasks\\n• Large Model API for complex reasoning tasks\\n• Model Cache for storing frequently used responses to reduce API calls\\n• CloudWatch to monitor system health and costs\\nFig 5.2: A serverless architecture where Lambda Controller makes \\nintelligent decisions about request handling\\nLambda - \\nSmall Tasks\\nLarge Model \\nAPI\\nMedium Model \\nAPI\\nSmall \\nModel API\\nModel Cache\\nLambda - \\nComplex Tasks\\nLambda - \\nMedium Tasks\\nSQS Queue\\nLambda Controller\\nCloudWatch\\nAPI Gateway'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 83, 'page_label': '84'}, page_content='84\\nMastering AI Agents\\nPlanning Failures\\nEffective planning is crucial for agents \\nto perform complex tasks. Planning \\nenables agents to anticipate future \\nstates, make informed decisions, and \\nexecute tasks in a structured manner. \\nWithout effective planning, agents may \\nstruggle to achieve desired outcomes. \\nHowever, LLMs often struggle with \\nplanning, as it requires strong reasoning \\nabilities and the ability to anticipate \\nfuture states.\\nTask Decomposition\\nBreak down tasks into smaller, \\nmanageable subtasks.\\nMulti-Plan Selection\\nGenerate multiple plans and select the \\nmost appropriate one based on the \\ncontext.\\nReflection and Refinement\\nContinuously refine plans based on new \\ninformation and feedback.and scale \\ncomputational resources efficiently. \\nDesign a serverless system to save \\nwasting of resources. (See Fig 5.2.)\\nFig 5.3: A simple illustration of how an agent \\nplans and executes complex task decomposition, \\nmulti-plan selection, and continuous refinement\\nTask Analysis\\nTask Complete \\nTask Decomposition\\nPlan Generation\\nPlan Evaluation\\nSelected Plan\\nExecution\\nSubtask 1\\nPlan A\\nSubtask 1\\nPlan B\\nSubtask 1\\nPlan C\\nComplex Task Input\\nReflection\\nSuccess\\nFeedback \\nLoop'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 84, 'page_label': '85'}, page_content='85\\nMastering AI Agents\\nReasoning Failures\\nReasoning is a fundamental capability \\nthat enables agents to make decisions, \\nsolve problems, and understand \\ncomplex environments. Strong \\nreasoning skills are essential for agents \\nto interact effectively with complex \\nenvironments and achieve desired \\noutcomes. LLMs lacking strong \\nreasoning skills may struggle with tasks \\nthat require multi-step logic or nuanced \\njudgment. (See Fig 5.4)\\nEnhance Reasoning Capabilities\\nUse prompting techniques like Reflexion \\nto enhance the reasoning capabilities. \\nIncorporate external reasoning modules \\nthat can assist the agent in complex \\ndecision-making processes. These \\nmodules can include specialized \\nalgorithms for logical reasoning, \\nprobabilistic inference, or symbolic \\ncomputation.\\nFinetune LLM\\nEstablish training with data generated \\nwith a human in the loop. Feedback \\nloops allow the agent to learn from its \\nmistakes and refine its reasoning over \\ntime. You can use data with traces \\nof reasoning that teach the model to \\nreason or plan in various scenarios.\\nUse Specialized Agents\\nDevelop specialized agents that focus \\non specific reasoning tasks to improve \\noverall performance.\\nFig 5.4: A simple illustration \\nof how you can enhance \\nthe capabilities of an LLM\\nInitial Response\\nSpecialized Module\\nImproved Answer\\nHuman Feedback\\nSelf-Review\\nReasoning Check\\nFinal Answer\\nUser Question\\nLearning\\nLooks Good\\nNeeds Improvement\\nLogic Helper For \\nClear, Logic Path\\nProbability Helper For \\nLikely Different Outcomes'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 85, 'page_label': '86'}, page_content='86\\nMastering AI Agents\\nTool Calling Failures\\nOne key benefit of agent abstraction \\nover prompting base language models \\nis the ability to solve complex problems \\nby calling multiple tools to interact with \\nexternal systems and data sources. \\nRobust tool calling mechanisms ensure \\nagents can perform complex tasks by \\nleveraging various tools accurately and \\nefficiently. However, agents often face \\nchallenges in effectively calling and \\nusing these tools. Tool calling failures \\ncan occur due to incorrect parameter \\npassing, misinterpretation of tool \\noutputs, or failures in integrating tool \\nresults into the agent’s workflow.\\nDefine Clear Parameters\\nEnsure that tools have well-defined \\nparameters and usage guidelines for \\nyou.\\nValidate Tool Outputs\\nImplement validation checks to ensure \\nthat tool outputs are accurate and \\nrelevant.\\nTool Selection Verification\\nUse a verification layer to check if the \\ntool selected is correct for the job.\\nProduction Issues\\nGuardrails\\nGuardrails help ensure that agents \\nadhere to safety protocols and \\nregulatory requirements. This is \\nparticularly important in sensitive \\ndomains such as healthcare, \\nfinance, and legal services, where \\nnon-compliance can have severe \\nconsequences. Guardrails define the \\noperational limits within which agents \\ncan function.\\nImplement rule-based filters and \\nvalidation mechanisms to monitor and \\ncontrol the actions and outputs of AI \\nagents.\\nContent Filters\\nUse predefined rules to filter \\ninappropriate, offensive, or harmful \\ncontent. For example, content filters can \\nscan the agent’s outputs for prohibited \\nwords or phrases and block or modify \\nresponses that contain such content.\\nInput Validation\\nBefore processing, inputs received by \\nthe agent must be validated to ensure \\nthey meet specific criteria. This can \\nprevent malicious or malformed inputs \\nfrom causing unintended behavior.\\nAction Constraints\\nDefine constraints on the actions that \\nagents can perform. For example, an \\nagent managing financial transactions \\nshould have rules that prevent it \\nfrom initiating transactions above a \\ncertain threshold without additional \\nauthorization.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 86, 'page_label': '87'}, page_content='87\\nMastering AI Agents\\nIncorporate human-in-the-loop \\nmechanisms to provide oversight and \\nintervention capabilities.\\nApproval Workflows:\\nImplement workflows where certain \\nactions or outputs require human \\napproval before execution. For example, \\nan agent generating legal documents \\ncan have its drafts reviewed by a human \\nexpert before finalization.\\nFeedback Loops:\\nAllow humans to provide feedback on \\nthe agent’s performance and outputs. \\nYou can use this feedback to refine the \\nagent’s behavior and improve future \\ninteractions.\\nEscalation Protocols:\\nEstablish protocols for escalating \\ncomplex or sensitive tasks to human \\noperators. For example, if an agent \\nencounters a situation it cannot handle, \\nit can escalate the issue to a human \\nsupervisor for resolution.\\nDevelop and enforce ethical and \\ncompliance frameworks to guide the \\nbehavior of AI agents.\\nEthical Guidelines:\\nEstablish ethical guidelines that outline \\nthe principles and values the agent must \\nadhere to. These guidelines can cover \\nareas such as fairness, transparency, \\nand accountability.\\nCompliance Checks:\\nImplement compliance checks to ensure \\nthat the agent’s actions and outputs \\nalign with regulatory requirements and \\norganizational policies. For example, \\nan agent handling personal data must \\ncomply with data protection regulations \\nsuch as GDPR.\\nAudit Trails:\\nMaintain audit trails that record the \\nagent’s actions and decisions. This \\nallows for retrospective analysis and \\naccountability, ensuring that any \\ndeviations from ethical or compliance \\nstandards can be identified and \\naddressed.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 87, 'page_label': '88'}, page_content='88\\nMastering AI Agents\\nAgent Scaling\\nScaling agents to handle increased \\nworkloads or more complex tasks \\nis a significant challenge. As the \\nnumber of agents or the complexity of \\ninteractions grows, the system must \\nefficiently manage resources, maintain \\nperformance, and ensure reliability.\\nScalable Architectures\\nDesign architectures that can efficiently \\nmanage increased workloads and \\ncomplexity. Implement a microservices \\narchitecture where each agent or group \\nof agents operates as an independent \\nservice. This allows for easier scaling \\nand management of individual \\ncomponents without affecting the entire \\nsystem.\\nResource Management\\nIntegrate load balancers to distribute \\nincoming requests evenly across \\nmultiple agents. This prevents any \\nsingle agent service from becoming \\noverwhelmed and ensures a more \\nefficient use of resources.\\nMonitor Performance\\nImplement real-time monitoring tools \\nto track each agent’s performance. \\nMetrics such as response time, resource \\nutilization, and error rates should be \\ncontinuously monitored to identify \\npotential issues. (See Fig 5.5) \\nPerformance Tracker\\nAuto Scaler\\nAI Agent 1 AI Agent 2\\nUser Requests\\nAI Agent 3\\nMonitoring\\nAI Agent Pool \\nScale Up/Down \\nLoad Balancer\\nFig 5.5: An illustration that shows \\nhow you can add monitoring and load \\nbalancers for easy scale-up and down'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 88, 'page_label': '89'}, page_content='89\\nMastering AI Agents\\nFault Tolerance\\nAI agents need to be fault-tolerant \\nto ensure that they can recover \\nfrom errors and continue operating \\neffectively. Without robust fault \\ntolerance mechanisms, agents may \\nfail to handle unexpected situations, \\nleading to system crashes or degraded \\nperformance. (See Fig 5.6)\\nRedundancy\\nDeploy multiple instances of AI \\nagents running in parallel. If one \\ninstance fails, the other instances can \\ncontinue processing requests without \\ninterruption. This approach ensures high \\navailability and minimizes downtime.\\nAutomated Recovery\\nIncorporate intelligent retry mechanisms \\nthat automatically attempt to recover \\nfrom transient errors. This includes \\nexponential backoff strategies, where \\nthe retry interval increases progressively \\nafter each failed attempt, reducing \\nthe risk of overwhelming the system. \\nDevelop self-healing mechanisms that \\nautomatically restart or replace failed \\nagent instances.\\nStateful Recovery\\nEnsure that AI agents can recover their \\nstate after a failure. This involves using \\npersistent storage to save the agent’s \\nstate and context, allowing it to resume \\noperations from the last known good \\nstate after a restart.\\nPrimary Agent \\nBackup Agent 1 Backup Agent 2\\nSwitch to Backup Process Task\\nRetry LogicSave State\\nTask Complete Persistent Storage\\nYour Task\\nRedundant \\nAgents\\nSuccess\\nPeriodic\\nNo Yes\\nFailure Check \\nHealth\\nError \\nOccurs?\\nBackoff Timer\\nFig 5.6: Fault-tolerant \\nmechanism for AI agents to \\nquickly recover from errors and \\ncontinue operating effectively'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 89, 'page_label': '90'}, page_content='90\\nMastering AI Agents\\nInfinite Looping\\nLooping mechanisms are essential for \\nagents to perform iterative tasks and \\nrefine their actions based on feedback. \\nAgents can sometimes get stuck in \\nloops, repeatedly performing the same \\nactions without progressing toward their \\ngoals. (See Fig 5.7)\\nClear Termination Conditions\\nImplement clear criteria for success and \\nmechanisms to break out of loops.\\nEnhance Reasoning and Planning\\nImprove the agent’s reasoning and \\nplanning capabilities to prevent infinite \\nlooping.\\nMonitor Agent Behavior\\nMonitor agent behavior and adjust to \\nprevent looping issues.\\nReasoning AdjustSuccess\\nTask Analysis \\nPlanning\\nReasoning\\nLoop Check\\nProgress\\nTerminate\\nReceive Task\\nDefine Goal & Steps \\nGoal Achieved\\nReturn Result Return Best Solution\\nGenerate Solution\\nNo Progress\\nNew Approach\\nCheck Progress\\nUnder Max Steps Exceeds Max Steps\\nFig 5.7: A simple \\nstrategy to prevent \\ninfinite looping'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 90, 'page_label': '91'}, page_content='91\\nMastering AI Agents\\nThrough the above examples and workflow diagrams (Fig 5.1 to Fig 5.6), you’ll \\nnotice that while building AI agents presents numerous challenges, understanding and \\naddressing these common failure points is necessary for success.\\nBy implementing proper guardrails, ensuring robust error handling, and designing scalable \\narchitectures, you can create agents that work reliably and provide real value in production \\nenvironments.\\nThat said, remember that building effective agents is an iterative process.\\nAlways start small, test thoroughly, and gradually expand your agent’s capabilities as you \\nlearn from real-world usage. Pay special attention to the fundamentals we’ve covered—\\nfrom clear task definition and evaluation to proper planning and reasoning capabilities. \\nThis will help you establish a strong foundation when you begin to experiment with your AI \\nagents.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 91, 'page_label': '92'}, page_content='92\\nMastering AI Agents\\nGlossary\\nTerm Description\\nLarge Language Model (LLM) An advanced AI model that can understand and generate human-like text by \\npredicting the next word in a sequence.\\nAI Agent Software application powered by large language models that autonomously perform \\nspecific tasks and makes complex decisions.\\nAgent-Based System An approach where software agents work independently to solve problems through \\ndecision-making and interactions.\\nTask Automation The process of using AI to perform repetitive or complex tasks without human \\nintervention.\\nSystem Latency The time delay between when an AI agent receives input and when it provides a \\nresponse.\\nEntity Memory A specialized form of AI memory that maintains detailed information about specific \\nentities (people, organizations, concepts) across multiple interactions.\\nHuman-in-the-Loop (HITL) A system design approach that integrates human oversight and intervention points \\nwithin automated AI processes.\\nMulti-Agent Pattern A structured approach to organizing multiple AI agents› interactions, including \\nhierarchical, sequential, and dynamic patterns.\\nRole-Based Agent Design An architectural approach where AI agents are assigned specific roles with defined \\nresponsibilities, tools, and interaction patterns within a larger system.\\nState Management Systematically tracking and controlling an AI agent›s internal conditions, memory, and \\ncontext throughout its operation cycle.\\nContext Window Utilization A metric measuring how efficiently an AI agent uses its available processing capacity \\nfor analyzing and retaining information\\nLLM Call Error Rate A critical reliability metric tracking the frequency of failed API requests and processing \\nerrors when an AI agent interacts with its underlying language model.\\nLatency per Tool Call A performance indicator measuring the time delay between an AI agent›s request to \\nuse a specific tool and receiving the tool›s response.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.1 (Windows)', 'creationdate': '2025-02-14T12:31:53+05:00', 'moddate': '2025-02-14T12:33:59+05:00', 'trapped': '/False', 'source': 'data\\\\agent_ai.pdf', 'total_pages': 93, 'page': 92, 'page_label': '93'}, page_content='93\\nMastering AI Agents\\nOutput Format Success Rate A quality metric assessing how accurately an AI agent adheres to specified formatting \\nrequirements and presentation standards across different user roles and contexts.\\nSteps per Task An efficiency metric tracking the number of discrete operations an AI agent requires to \\ncomplete a given task.\\nTask Completion Rate A comprehensive performance indicator measuring the percentage of assignments an \\nAI agent successfully completes without human intervention.\\nTool Selection Accuracy A metric evaluating how appropriately an AI agent chooses specific tools or methods \\nfrom its available toolkit based on task requirements and complexity.\\nToken Usage per Interaction A resource efficiency metric tracking how many computational units (tokens) an AI \\nagent consumes during task processing\\nHierarchical Design A system architecture where specialized AI agents handle specific tasks, reducing the \\ncomplexity of steering a single agent.\\nPrompting Techniques Research-backed methods to guide LLM behavior and reduce hallucinations in AI \\nagents.\\nReflexion A specialized prompting technique that enhances an AI agent›s reasoning capabilities \\nthrough self-reflection and improvement.\\nServerless Architecture A cloud-based system design where computational resources are dynamically \\nallocated based on AI agent workload demands.\\nTask Decomposition The process of breaking down complex assignments into smaller, manageable \\nsubtasks for AI agents to handle effectively.\\nTool Calling The mechanism by which AI agents interact with external systems and data sources \\nto solve complex problems through multiple tool interactions.')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65a3f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meta_data(docs: List[Document]) -> List[Document]:\n",
    "\n",
    "    min_docs: List[Document] = []\n",
    "\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source\" , \"page\")\n",
    "        min_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata = {\"source\" : src}\n",
    "\n",
    "            )\n",
    "        )\n",
    "    return min_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bdbd37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_doc = extract_meta_data(extracted_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac2835a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\agent_ai.pdf'}, page_content=''),\n",
       " Document(metadata={'source': 'data\\\\agent_ai.pdf'}, page_content='2\\nMastering AI Agents\\nPreface\\nIn our previous e-book, “Mastering RAG,” our goal was clear: building enterprise-grade \\nRAG systems, productionizing them, monitoring their performance, and improving them. \\nAt the core of it, we understood how RAG systems enhance an LLM’s ability to work with \\nspecific knowledge by providing relevant context. \\nIn this e-book, we’re taking a step further and asking, “How do we use LLMs to \\naccomplish end-to-end tasks?” This singular question opens up a door: AI agents. A RAG \\nsystem helps an LLM provide accurate answers based on given context. An AI agent \\ntakes that answer and actually does something with it — makes decisions, executes \\ntasks, or coordinates multiple steps to achieve a goal.\\nA RAG-enhanced LLM could help answer questions about policy details by pulling relevant \\ninformation. But an AI agent could actually process the claim end-to-end by analyzing the \\ndocumentation, checking policy compliance, calculating payments, and even coordinating \\nwith other systems or agents when needed. \\nThe ideas behind agents has existed for years. It can be a software program or another \\ncomputational entity that can accept input from its environment and take actions based \\non rules. With AI agents, you’re getting what has never been there before: the ability to \\nunderstand the context without predefined rules, the capacity to tune decisions based on \\ncontext, and learning from every interaction. What you’re getting is not just a bot working \\nwith a fixed set of rules but a system capable of making advanced decisions in real-time. \\nCompanies have quickly adapted, adopted, and integrated AI agents into their workflows. \\nCapgemini’s research found that “10% of organizations already use AI agents, more than \\nhalf plan to use them in 2025 and 82% plan to integrate them within the next three years.”'),\n",
       " Document(metadata={'source': 'data\\\\agent_ai.pdf'}, page_content='3\\nMastering AI Agents\\nThis e-book aims to be your go-to guide for all things AI agents. If you’re a leader looking \\nto guide your company to build successful agentic applications, this e-book can serve \\nas a great guide to get you started. We also explore approaches to measuring how well \\nyour AI agents perform, as well as common pitfalls you may encounter when designing, \\nmeasuring, and improving them. \\nThe book is divided into five chapters: \\nChapter 1 introduces AI agents, their optimal applications, and scenarios where they \\nmight be excessive. It covers various agent types and includes three real-world use cases \\nto illustrate their potential. \\nChapter 2 details three frameworks—LangGraph, Autogen, and CrewAI—with evaluation \\ncriteria to help choose the best fit. It ends with case studies of companies using these \\nframeworks for specific AI tasks.\\nChapter 3 explores the evaluation of an AI agent through a step-by-step example of a \\nfinance research agent. \\nChapter 4 explores how to measure agent performance across systems, task completion, \\nquality control, and tool interaction, supported by five detailed use cases. \\nChapter 5 addresses why many AI agents fail and offers practical solutions for successful \\nAI deployment.\\nWe hope this book will be a great stepping stone in your journey to build trustworthy \\nagentic systems. \\n- Pratik Bhavsar'),\n",
       " Document(metadata={'source': 'data\\\\agent_ai.pdf'}, page_content='Contents\\nTypes of AI Agents\\nWhen to Use Agents?\\nWhen Not to Use Agents?\\n10 Questions to Ask Before You \\nConsider an AI Agent\\n3 Interesting Real-World Use \\nCases of AI Agents\\n10 30\\n21\\n31\\n31\\n32\\n33\\n34\\n34\\n35\\n35\\n35\\n37\\n40\\n22\\n23\\n25\\nChapter 1:\\nWhat are AI agents\\nChapter 2:\\nFrameworks for \\nBuilding Agents\\nLangGraph vs. AutoGen vs. \\nCrewAI\\nPractical Considerations\\nWhat Tools and Functionalities Do \\nThey Support?\\nHow Well Do They Maintain the \\nContext?\\nAre They Well-Organized and Easy \\nto Interpret?\\nWhat’s the Quality of \\nDocumentation?\\nDo They Provide Multi-Agent \\nSupport?\\nWhat About Caching?\\nLooking at the Replay Functionality\\nWhat About Code Execution?\\nHuman in the Loop Support?\\nPopular Use Cases Centered \\nAround These Frameworks\\n7/27 28/43'),\n",
       " Document(metadata={'source': 'data\\\\agent_ai.pdf'}, page_content='5\\nMastering AI Agents\\nRequirements\\nDefining the Problem\\nDefine the React Agent\\nState Management\\nCreate the Graph\\nCreate the LLM Judge\\nUse Galileo Callbacks\\n44\\n44\\n45\\n46\\n47\\n54\\n55\\n63\\n66\\n69\\n72\\n75\\nChapter 3:\\nHow to Evaluate Agents\\n44/61\\nChapter 4:\\nMetrics for Evaluating \\nAI Agents\\n62/79\\nCase Study 1: Advancing the \\nClaims Processing Agent\\nCase Study 2: Optimizing the Tax \\nAudit Agent\\nCase Study 3: Elevating the Stock \\nAnalysis Agent\\nCase Study 4: Upgrading the \\nCoding Agent\\nCase Study 5: Enhancing the Lead \\nScoring Agent')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1eea3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets do a chunking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9713cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunking(minimal_doc):\n",
    "    text_chunk = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=100,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "\n",
    "    split_chunks = text_chunk.split_documents(minimal_doc)\n",
    "\n",
    "    return split_chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "02f600c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_doc = chunking(minimal_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e30235d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1507"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ec2aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
